{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow_datasets\r\n",
      "  Downloading tensorflow_datasets-4.7.0-py3-none-any.whl (4.7 MB)\r\n",
      "     |████████████████████████████████| 4.7 MB 11.3 MB/s            \r\n",
      "\u001B[?25hRequirement already satisfied: importlib-resources in ./venv/lib/python3.7/site-packages (from tensorflow_datasets) (5.10.1)\r\n",
      "Collecting protobuf>=3.12.2\r\n",
      "  Downloading protobuf-4.21.11-cp37-abi3-manylinux2014_x86_64.whl (409 kB)\r\n",
      "     |████████████████████████████████| 409 kB 8.2 MB/s            \r\n",
      "\u001B[?25hCollecting toml\r\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\r\n",
      "Requirement already satisfied: six in ./venv/lib/python3.7/site-packages (from tensorflow_datasets) (1.16.0)\r\n",
      "Collecting absl-py\r\n",
      "  Downloading absl_py-1.3.0-py3-none-any.whl (124 kB)\r\n",
      "     |████████████████████████████████| 124 kB 10.9 MB/s            \r\n",
      "\u001B[?25hCollecting tensorflow-metadata\r\n",
      "  Downloading tensorflow_metadata-1.12.0-py3-none-any.whl (52 kB)\r\n",
      "     |████████████████████████████████| 52 kB 1.1 MB/s             \r\n",
      "\u001B[?25hCollecting termcolor\r\n",
      "  Downloading termcolor-2.1.1-py3-none-any.whl (6.2 kB)\r\n",
      "Requirement already satisfied: typing-extensions in ./venv/lib/python3.7/site-packages (from tensorflow_datasets) (4.4.0)\r\n",
      "Collecting dill\r\n",
      "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\r\n",
      "     |████████████████████████████████| 110 kB 11.1 MB/s            \r\n",
      "\u001B[?25hCollecting numpy\r\n",
      "  Downloading numpy-1.21.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\r\n",
      "     |████████████████████████████████| 15.7 MB 12.2 MB/s            \r\n",
      "\u001B[?25hCollecting etils[epath]\r\n",
      "  Downloading etils-0.9.0-py3-none-any.whl (140 kB)\r\n",
      "     |████████████████████████████████| 140 kB 11.1 MB/s            \r\n",
      "\u001B[?25hCollecting requests>=2.19.0\r\n",
      "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\r\n",
      "     |████████████████████████████████| 62 kB 2.1 MB/s             \r\n",
      "\u001B[?25hCollecting tqdm\r\n",
      "  Using cached tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\r\n",
      "Collecting promise\r\n",
      "  Using cached promise-2.3.tar.gz (19 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25hCollecting certifi>=2017.4.17\r\n",
      "  Downloading certifi-2022.12.7-py3-none-any.whl (155 kB)\r\n",
      "     |████████████████████████████████| 155 kB 11.4 MB/s            \r\n",
      "\u001B[?25hCollecting charset-normalizer<3,>=2\r\n",
      "  Using cached charset_normalizer-2.1.1-py3-none-any.whl (39 kB)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.7/site-packages (from requests>=2.19.0->tensorflow_datasets) (3.4)\r\n",
      "Collecting urllib3<1.27,>=1.21.1\r\n",
      "  Using cached urllib3-1.26.13-py2.py3-none-any.whl (140 kB)\r\n",
      "Requirement already satisfied: zipp in ./venv/lib/python3.7/site-packages (from etils[epath]->tensorflow_datasets) (3.11.0)\r\n",
      "Collecting protobuf>=3.12.2\r\n",
      "  Downloading protobuf-3.20.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\r\n",
      "     |████████████████████████████████| 1.0 MB 10.9 MB/s            \r\n",
      "\u001B[?25hCollecting googleapis-common-protos<2,>=1.52.0\r\n",
      "  Downloading googleapis_common_protos-1.57.0-py2.py3-none-any.whl (217 kB)\r\n",
      "     |████████████████████████████████| 217 kB 11.0 MB/s            \r\n",
      "\u001B[?25hBuilding wheels for collected packages: promise\r\n",
      "  Building wheel for promise (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21503 sha256=6b3fff96fcbc8fa031a3c10a61ef84c02f6755ae66494a7bdf42c06e61c83118\r\n",
      "  Stored in directory: /home/deniz/.cache/pip/wheels/29/93/c6/762e359f8cb6a5b69c72235d798804cae523bbe41c2aa8333d\r\n",
      "Successfully built promise\r\n",
      "Installing collected packages: protobuf, etils, urllib3, googleapis-common-protos, charset-normalizer, certifi, absl-py, tqdm, toml, termcolor, tensorflow-metadata, requests, promise, numpy, dill, tensorflow-datasets\r\n",
      "Successfully installed absl-py-1.3.0 certifi-2022.12.7 charset-normalizer-2.1.1 dill-0.3.6 etils-0.9.0 googleapis-common-protos-1.57.0 numpy-1.21.6 promise-2.3 protobuf-3.20.3 requests-2.28.1 tensorflow-datasets-4.7.0 tensorflow-metadata-1.12.0 termcolor-2.1.1 toml-0.10.2 tqdm-4.64.1 urllib3-1.26.13\r\n",
      "\u001B[33mWARNING: You are using pip version 21.3.1; however, version 22.3.1 is available.\r\n",
      "You should consider upgrading via the '/home/deniz/PycharmProjects/mobilenet_finetune_exo/venv/bin/python -m pip install --upgrade pip' command.\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow_datasets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\r\n",
      "  Downloading tensorflow-2.11.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\r\n",
      "     |████████████████████████████████| 588.3 MB 14 kB/s              \r\n",
      "\u001B[?25hCollecting wrapt>=1.11.0\r\n",
      "  Downloading wrapt-1.14.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (75 kB)\r\n",
      "     |████████████████████████████████| 75 kB 4.6 MB/s             \r\n",
      "\u001B[?25hCollecting keras<2.12,>=2.11.0\r\n",
      "  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\r\n",
      "     |████████████████████████████████| 1.7 MB 10.9 MB/s            \r\n",
      "\u001B[?25hCollecting google-pasta>=0.1.1\r\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\r\n",
      "Collecting grpcio<2.0,>=1.24.3\r\n",
      "  Downloading grpcio-1.51.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\r\n",
      "     |████████████████████████████████| 4.8 MB 10.9 MB/s            \r\n",
      "\u001B[?25hRequirement already satisfied: absl-py>=1.0.0 in ./venv/lib/python3.7/site-packages (from tensorflow) (1.3.0)\r\n",
      "Collecting flatbuffers>=2.0\r\n",
      "  Downloading flatbuffers-22.12.6-py2.py3-none-any.whl (26 kB)\r\n",
      "Collecting libclang>=13.0.0\r\n",
      "  Downloading libclang-14.0.6-py2.py3-none-manylinux2010_x86_64.whl (14.1 MB)\r\n",
      "     |████████████████████████████████| 14.1 MB 12.2 MB/s            \r\n",
      "\u001B[?25hCollecting tensorboard<2.12,>=2.11\r\n",
      "  Downloading tensorboard-2.11.0-py3-none-any.whl (6.0 MB)\r\n",
      "     |████████████████████████████████| 6.0 MB 10.8 MB/s            \r\n",
      "\u001B[?25hCollecting protobuf<3.20,>=3.9.2\r\n",
      "  Downloading protobuf-3.19.6-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\r\n",
      "     |████████████████████████████████| 1.1 MB 11.1 MB/s            \r\n",
      "\u001B[?25hCollecting tensorflow-estimator<2.12,>=2.11.0\r\n",
      "  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\r\n",
      "     |████████████████████████████████| 439 kB 10.8 MB/s            \r\n",
      "\u001B[?25hCollecting opt-einsum>=2.3.2\r\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\r\n",
      "Requirement already satisfied: packaging in ./venv/lib/python3.7/site-packages (from tensorflow) (22.0)\r\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\r\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.28.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\r\n",
      "     |████████████████████████████████| 2.4 MB 11.1 MB/s            \r\n",
      "\u001B[?25hRequirement already satisfied: typing-extensions>=3.6.6 in ./venv/lib/python3.7/site-packages (from tensorflow) (4.4.0)\r\n",
      "Collecting h5py>=2.9.0\r\n",
      "  Downloading h5py-3.7.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.1 MB)\r\n",
      "     |████████████████████████████████| 4.1 MB 11.1 MB/s            \r\n",
      "\u001B[?25hRequirement already satisfied: numpy>=1.20 in ./venv/lib/python3.7/site-packages (from tensorflow) (1.21.6)\r\n",
      "Requirement already satisfied: setuptools in ./venv/lib/python3.7/site-packages (from tensorflow) (60.2.0)\r\n",
      "Collecting astunparse>=1.6.0\r\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\r\n",
      "Collecting gast<=0.4.0,>=0.2.1\r\n",
      "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\r\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./venv/lib/python3.7/site-packages (from tensorflow) (2.1.1)\r\n",
      "Requirement already satisfied: six>=1.12.0 in ./venv/lib/python3.7/site-packages (from tensorflow) (1.16.0)\r\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./venv/lib/python3.7/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\r\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\r\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\r\n",
      "Collecting google-auth<3,>=1.6.3\r\n",
      "  Downloading google_auth-2.15.0-py2.py3-none-any.whl (177 kB)\r\n",
      "     |████████████████████████████████| 177 kB 11.0 MB/s            \r\n",
      "\u001B[?25hCollecting tensorboard-plugin-wit>=1.6.0\r\n",
      "  Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\r\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\r\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\r\n",
      "Collecting markdown>=2.6.8\r\n",
      "  Downloading Markdown-3.4.1-py3-none-any.whl (93 kB)\r\n",
      "     |████████████████████████████████| 93 kB 2.8 MB/s             \r\n",
      "\u001B[?25hCollecting werkzeug>=1.0.1\r\n",
      "  Downloading Werkzeug-2.2.2-py3-none-any.whl (232 kB)\r\n",
      "     |████████████████████████████████| 232 kB 10.9 MB/s            \r\n",
      "\u001B[?25hRequirement already satisfied: requests<3,>=2.21.0 in ./venv/lib/python3.7/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.28.1)\r\n",
      "Collecting rsa<5,>=3.1.4\r\n",
      "  Using cached rsa-4.9-py3-none-any.whl (34 kB)\r\n",
      "Collecting pyasn1-modules>=0.2.1\r\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\r\n",
      "Collecting cachetools<6.0,>=2.0.0\r\n",
      "  Downloading cachetools-5.2.0-py3-none-any.whl (9.3 kB)\r\n",
      "Collecting requests-oauthlib>=0.7.0\r\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\r\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in ./venv/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (5.1.0)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./venv/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (1.26.13)\r\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in ./venv/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2.1.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (3.4)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2022.12.7)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in ./venv/lib/python3.7/site-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow) (2.1.1)\r\n",
      "Requirement already satisfied: zipp>=0.5 in ./venv/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (3.11.0)\r\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\r\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\r\n",
      "Collecting oauthlib>=3.0.0\r\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\r\n",
      "     |████████████████████████████████| 151 kB 11.1 MB/s            \r\n",
      "\u001B[?25hInstalling collected packages: pyasn1, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, protobuf, markdown, grpcio, google-auth-oauthlib, wrapt, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard, opt-einsum, libclang, keras, h5py, google-pasta, gast, flatbuffers, astunparse, tensorflow\r\n",
      "  Attempting uninstall: protobuf\r\n",
      "    Found existing installation: protobuf 3.20.3\r\n",
      "    Uninstalling protobuf-3.20.3:\r\n",
      "      Successfully uninstalled protobuf-3.20.3\r\n",
      "Successfully installed astunparse-1.6.3 cachetools-5.2.0 flatbuffers-22.12.6 gast-0.4.0 google-auth-2.15.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.51.1 h5py-3.7.0 keras-2.11.0 libclang-14.0.6 markdown-3.4.1 oauthlib-3.2.2 opt-einsum-3.3.0 protobuf-3.19.6 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.11.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.11.0 tensorflow-estimator-2.11.0 tensorflow-io-gcs-filesystem-0.28.0 werkzeug-2.2.2 wrapt-1.14.1\r\n",
      "\u001B[33mWARNING: You are using pip version 21.3.1; however, version 22.3.1 is available.\r\n",
      "You should consider upgrading via the '/home/deniz/PycharmProjects/mobilenet_finetune_exo/venv/bin/python -m pip install --upgrade pip' command.\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Pillow\r\n",
      "  Downloading Pillow-9.3.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\r\n",
      "     |████████████████████████████████| 3.2 MB 11.0 MB/s            \r\n",
      "\u001B[?25hInstalling collected packages: Pillow\r\n",
      "Successfully installed Pillow-9.3.0\r\n",
      "\u001B[33mWARNING: You are using pip version 21.3.1; however, version 22.3.1 is available.\r\n",
      "You should consider upgrading via the '/home/deniz/PycharmProjects/mobilenet_finetune_exo/venv/bin/python -m pip install --upgrade pip' command.\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install Pillow"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "outputs": [],
   "source": [
    "list_ds = tf.data.Dataset.list_files('./spectrogram_data_color/*.png', shuffle=False)\n",
    "list_ds = list_ds.shuffle(image_count, reshuffle_each_iteration=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'./spectrogram_data_color/7003_0_1_img.png'\n",
      "b'./spectrogram_data_color/5099_0_1_img.png'\n",
      "b'./spectrogram_data_color/12183_2_1_img.png'\n",
      "b'./spectrogram_data_color/7752_0_1_img.png'\n",
      "b'./spectrogram_data_color/19032_0_1_img.png'\n"
     ]
    }
   ],
   "source": [
    "for f in val_ds.take(5):\n",
    "  print(f.numpy())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "aaa = './spectrogram_data_color/0_0_1_img.png'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "'0'"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aaa.split('/')[2].split('_')[1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(), dtype=string, numpy=b'0'>"
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.split(tf.strings.split(aaa, os.path.sep)[-1], '_')[1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Level Walking', 'Ramp Descent', 'Ramp Ascent', 'Stair Descent', 'Stair Ascent']\n"
     ]
    }
   ],
   "source": [
    "class_names = ['Level Walking', 'Ramp Descent', 'Ramp Ascent', 'Stair Descent', 'Stair Ascent']\n",
    "print(class_names)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "image_count = tf.data.experimental.cardinality(list_ds).numpy()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "outputs": [],
   "source": [
    "val_size = int(image_count * 0.2)\n",
    "train_ds = list_ds.skip(val_size)\n",
    "val_ds = list_ds.take(val_size)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16585\n",
      "4146\n"
     ]
    }
   ],
   "source": [
    "print(tf.data.experimental.cardinality(train_ds).numpy())\n",
    "print(tf.data.experimental.cardinality(val_ds).numpy())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(), dtype=int64, numpy=0>"
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.to_number(get_label(aaa), out_type=tf.dtypes.int64)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "outputs": [],
   "source": [
    "def get_label(file_path):\n",
    "  return tf.strings.to_number(tf.strings.split(tf.strings.split(file_path, os.path.sep)[-1], '_')[1], out_type=tf.dtypes.int64)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "outputs": [],
   "source": [
    "def decode_img(img):\n",
    "  # Convert the compressed string to a 3D uint8 tensor\n",
    "  img = tf.io.decode_jpeg(img, channels=3)\n",
    "  return img"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "outputs": [],
   "source": [
    "def process_path(file_path):\n",
    "  label = get_label(file_path)\n",
    "  # Load the raw data from the file as a string\n",
    "  img = tf.io.read_file(file_path)\n",
    "  img = decode_img(img)\n",
    "  return img, label"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "a bytes-like object is required, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_9885/1945201747.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mprocess_path\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mb'./spectrogram_data_color/19032_0_1_img.png'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/tmp/ipykernel_9885/1562990726.py\u001B[0m in \u001B[0;36mprocess_path\u001B[0;34m(file_path)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mprocess_path\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfile_path\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m   \u001B[0mlabel\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfile_path\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msplit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msep\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msplit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'_'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m   \u001B[0;31m# Load the raw data from the file as a string\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m   \u001B[0mimg\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mio\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread_file\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfile_path\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m   \u001B[0mimg\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdecode_img\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: a bytes-like object is required, not 'str'"
     ]
    }
   ],
   "source": [
    "process_path(b'./spectrogram_data_color/19032_0_1_img.png')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "outputs": [],
   "source": [
    "# Set `num_parallel_calls` so multiple images are loaded/processed in parallel.\n",
    "train_ds = train_ds.map(process_path, num_parallel_calls=16)\n",
    "val_ds = val_ds.map(process_path, num_parallel_calls=16)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape:  (224, 224, 3)\n",
      "Label:  1\n"
     ]
    }
   ],
   "source": [
    "for image, label in train_ds.take(1):\n",
    "  print(\"Image shape: \", image.numpy().shape)\n",
    "  print(\"Label: \", label.numpy())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "outputs": [],
   "source": [
    "val_ds = val_ds.batch(batch_size=32)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "outputs": [],
   "source": [
    "train_ds = train_ds.batch(batch_size=32)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "outputs": [
    {
     "data": {
      "text/plain": "TensorShape([32, 224, 224, 3])"
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for image_batch, label_batch in train_ds.take(1):\n",
    "   pass\n",
    "\n",
    "image_batch.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "IMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n",
    "\n",
    "# Create the base model from the pre-trained model MobileNet V2\n",
    "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.MobileNetV3Small(\n",
    "    input_shape=IMG_SHAPE,\n",
    "    include_top=False,\n",
    "    weights='imagenet'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 7, 7, 576)\n"
     ]
    }
   ],
   "source": [
    "feature_batch = base_model(image_batch)\n",
    "print(feature_batch.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "outputs": [],
   "source": [
    "base_model.trainable = False\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"MobilenetV3small\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_10 (InputLayer)          [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " rescaling_2 (Rescaling)        (None, 224, 224, 3)  0           ['input_10[0][0]']               \n",
      "                                                                                                  \n",
      " Conv (Conv2D)                  (None, 112, 112, 16  432         ['rescaling_2[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " Conv/BatchNorm (BatchNormaliza  (None, 112, 112, 16  64         ['Conv[0][0]']                   \n",
      " tion)                          )                                                                 \n",
      "                                                                                                  \n",
      " tf.__operators__.add_54 (TFOpL  (None, 112, 112, 16  0          ['Conv/BatchNorm[0][0]']         \n",
      " ambda)                         )                                                                 \n",
      "                                                                                                  \n",
      " re_lu_64 (ReLU)                (None, 112, 112, 16  0           ['tf.__operators__.add_54[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " tf.math.multiply_54 (TFOpLambd  (None, 112, 112, 16  0          ['re_lu_64[0][0]']               \n",
      " a)                             )                                                                 \n",
      "                                                                                                  \n",
      " multiply_36 (Multiply)         (None, 112, 112, 16  0           ['Conv/BatchNorm[0][0]',         \n",
      "                                )                                 'tf.math.multiply_54[0][0]']    \n",
      "                                                                                                  \n",
      " expanded_conv/depthwise/pad (Z  (None, 113, 113, 16  0          ['multiply_36[0][0]']            \n",
      " eroPadding2D)                  )                                                                 \n",
      "                                                                                                  \n",
      " expanded_conv/depthwise (Depth  (None, 56, 56, 16)  144         ['expanded_conv/depthwise/pad[0][\n",
      " wiseConv2D)                                                     0]']                             \n",
      "                                                                                                  \n",
      " expanded_conv/depthwise/BatchN  (None, 56, 56, 16)  64          ['expanded_conv/depthwise[0][0]']\n",
      " orm (BatchNormalization)                                                                         \n",
      "                                                                                                  \n",
      " re_lu_65 (ReLU)                (None, 56, 56, 16)   0           ['expanded_conv/depthwise/BatchNo\n",
      "                                                                 rm[0][0]']                       \n",
      "                                                                                                  \n",
      " expanded_conv/squeeze_excite/A  (None, 1, 1, 16)    0           ['re_lu_65[0][0]']               \n",
      " vgPool (GlobalAveragePooling2D                                                                   \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " expanded_conv/squeeze_excite/C  (None, 1, 1, 8)     136         ['expanded_conv/squeeze_excite/Av\n",
      " onv (Conv2D)                                                    gPool[0][0]']                    \n",
      "                                                                                                  \n",
      " expanded_conv/squeeze_excite/R  (None, 1, 1, 8)     0           ['expanded_conv/squeeze_excite/Co\n",
      " elu (ReLU)                                                      nv[0][0]']                       \n",
      "                                                                                                  \n",
      " expanded_conv/squeeze_excite/C  (None, 1, 1, 16)    144         ['expanded_conv/squeeze_excite/Re\n",
      " onv_1 (Conv2D)                                                  lu[0][0]']                       \n",
      "                                                                                                  \n",
      " tf.__operators__.add_55 (TFOpL  (None, 1, 1, 16)    0           ['expanded_conv/squeeze_excite/Co\n",
      " ambda)                                                          nv_1[0][0]']                     \n",
      "                                                                                                  \n",
      " re_lu_66 (ReLU)                (None, 1, 1, 16)     0           ['tf.__operators__.add_55[0][0]']\n",
      "                                                                                                  \n",
      " tf.math.multiply_55 (TFOpLambd  (None, 1, 1, 16)    0           ['re_lu_66[0][0]']               \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " expanded_conv/squeeze_excite/M  (None, 56, 56, 16)  0           ['re_lu_65[0][0]',               \n",
      " ul (Multiply)                                                    'tf.math.multiply_55[0][0]']    \n",
      "                                                                                                  \n",
      " expanded_conv/project (Conv2D)  (None, 56, 56, 16)  256         ['expanded_conv/squeeze_excite/Mu\n",
      "                                                                 l[0][0]']                        \n",
      "                                                                                                  \n",
      " expanded_conv/project/BatchNor  (None, 56, 56, 16)  64          ['expanded_conv/project[0][0]']  \n",
      " m (BatchNormalization)                                                                           \n",
      "                                                                                                  \n",
      " expanded_conv_1/expand (Conv2D  (None, 56, 56, 72)  1152        ['expanded_conv/project/BatchNorm\n",
      " )                                                               [0][0]']                         \n",
      "                                                                                                  \n",
      " expanded_conv_1/expand/BatchNo  (None, 56, 56, 72)  288         ['expanded_conv_1/expand[0][0]'] \n",
      " rm (BatchNormalization)                                                                          \n",
      "                                                                                                  \n",
      " re_lu_67 (ReLU)                (None, 56, 56, 72)   0           ['expanded_conv_1/expand/BatchNor\n",
      "                                                                 m[0][0]']                        \n",
      "                                                                                                  \n",
      " expanded_conv_1/depthwise/pad   (None, 57, 57, 72)  0           ['re_lu_67[0][0]']               \n",
      " (ZeroPadding2D)                                                                                  \n",
      "                                                                                                  \n",
      " expanded_conv_1/depthwise (Dep  (None, 28, 28, 72)  648         ['expanded_conv_1/depthwise/pad[0\n",
      " thwiseConv2D)                                                   ][0]']                           \n",
      "                                                                                                  \n",
      " expanded_conv_1/depthwise/Batc  (None, 28, 28, 72)  288         ['expanded_conv_1/depthwise[0][0]\n",
      " hNorm (BatchNormalization)                                      ']                               \n",
      "                                                                                                  \n",
      " re_lu_68 (ReLU)                (None, 28, 28, 72)   0           ['expanded_conv_1/depthwise/Batch\n",
      "                                                                 Norm[0][0]']                     \n",
      "                                                                                                  \n",
      " expanded_conv_1/project (Conv2  (None, 28, 28, 24)  1728        ['re_lu_68[0][0]']               \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " expanded_conv_1/project/BatchN  (None, 28, 28, 24)  96          ['expanded_conv_1/project[0][0]']\n",
      " orm (BatchNormalization)                                                                         \n",
      "                                                                                                  \n",
      " expanded_conv_2/expand (Conv2D  (None, 28, 28, 88)  2112        ['expanded_conv_1/project/BatchNo\n",
      " )                                                               rm[0][0]']                       \n",
      "                                                                                                  \n",
      " expanded_conv_2/expand/BatchNo  (None, 28, 28, 88)  352         ['expanded_conv_2/expand[0][0]'] \n",
      " rm (BatchNormalization)                                                                          \n",
      "                                                                                                  \n",
      " re_lu_69 (ReLU)                (None, 28, 28, 88)   0           ['expanded_conv_2/expand/BatchNor\n",
      "                                                                 m[0][0]']                        \n",
      "                                                                                                  \n",
      " expanded_conv_2/depthwise (Dep  (None, 28, 28, 88)  792         ['re_lu_69[0][0]']               \n",
      " thwiseConv2D)                                                                                    \n",
      "                                                                                                  \n",
      " expanded_conv_2/depthwise/Batc  (None, 28, 28, 88)  352         ['expanded_conv_2/depthwise[0][0]\n",
      " hNorm (BatchNormalization)                                      ']                               \n",
      "                                                                                                  \n",
      " re_lu_70 (ReLU)                (None, 28, 28, 88)   0           ['expanded_conv_2/depthwise/Batch\n",
      "                                                                 Norm[0][0]']                     \n",
      "                                                                                                  \n",
      " expanded_conv_2/project (Conv2  (None, 28, 28, 24)  2112        ['re_lu_70[0][0]']               \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " expanded_conv_2/project/BatchN  (None, 28, 28, 24)  96          ['expanded_conv_2/project[0][0]']\n",
      " orm (BatchNormalization)                                                                         \n",
      "                                                                                                  \n",
      " expanded_conv_2/Add (Add)      (None, 28, 28, 24)   0           ['expanded_conv_1/project/BatchNo\n",
      "                                                                 rm[0][0]',                       \n",
      "                                                                  'expanded_conv_2/project/BatchNo\n",
      "                                                                 rm[0][0]']                       \n",
      "                                                                                                  \n",
      " expanded_conv_3/expand (Conv2D  (None, 28, 28, 96)  2304        ['expanded_conv_2/Add[0][0]']    \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " expanded_conv_3/expand/BatchNo  (None, 28, 28, 96)  384         ['expanded_conv_3/expand[0][0]'] \n",
      " rm (BatchNormalization)                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_56 (TFOpL  (None, 28, 28, 96)  0           ['expanded_conv_3/expand/BatchNor\n",
      " ambda)                                                          m[0][0]']                        \n",
      "                                                                                                  \n",
      " re_lu_71 (ReLU)                (None, 28, 28, 96)   0           ['tf.__operators__.add_56[0][0]']\n",
      "                                                                                                  \n",
      " tf.math.multiply_56 (TFOpLambd  (None, 28, 28, 96)  0           ['re_lu_71[0][0]']               \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " multiply_37 (Multiply)         (None, 28, 28, 96)   0           ['expanded_conv_3/expand/BatchNor\n",
      "                                                                 m[0][0]',                        \n",
      "                                                                  'tf.math.multiply_56[0][0]']    \n",
      "                                                                                                  \n",
      " expanded_conv_3/depthwise/pad   (None, 31, 31, 96)  0           ['multiply_37[0][0]']            \n",
      " (ZeroPadding2D)                                                                                  \n",
      "                                                                                                  \n",
      " expanded_conv_3/depthwise (Dep  (None, 14, 14, 96)  2400        ['expanded_conv_3/depthwise/pad[0\n",
      " thwiseConv2D)                                                   ][0]']                           \n",
      "                                                                                                  \n",
      " expanded_conv_3/depthwise/Batc  (None, 14, 14, 96)  384         ['expanded_conv_3/depthwise[0][0]\n",
      " hNorm (BatchNormalization)                                      ']                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_57 (TFOpL  (None, 14, 14, 96)  0           ['expanded_conv_3/depthwise/Batch\n",
      " ambda)                                                          Norm[0][0]']                     \n",
      "                                                                                                  \n",
      " re_lu_72 (ReLU)                (None, 14, 14, 96)   0           ['tf.__operators__.add_57[0][0]']\n",
      "                                                                                                  \n",
      " tf.math.multiply_57 (TFOpLambd  (None, 14, 14, 96)  0           ['re_lu_72[0][0]']               \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " multiply_38 (Multiply)         (None, 14, 14, 96)   0           ['expanded_conv_3/depthwise/Batch\n",
      "                                                                 Norm[0][0]',                     \n",
      "                                                                  'tf.math.multiply_57[0][0]']    \n",
      "                                                                                                  \n",
      " expanded_conv_3/squeeze_excite  (None, 1, 1, 96)    0           ['multiply_38[0][0]']            \n",
      " /AvgPool (GlobalAveragePooling                                                                   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " expanded_conv_3/squeeze_excite  (None, 1, 1, 24)    2328        ['expanded_conv_3/squeeze_excite/\n",
      " /Conv (Conv2D)                                                  AvgPool[0][0]']                  \n",
      "                                                                                                  \n",
      " expanded_conv_3/squeeze_excite  (None, 1, 1, 24)    0           ['expanded_conv_3/squeeze_excite/\n",
      " /Relu (ReLU)                                                    Conv[0][0]']                     \n",
      "                                                                                                  \n",
      " expanded_conv_3/squeeze_excite  (None, 1, 1, 96)    2400        ['expanded_conv_3/squeeze_excite/\n",
      " /Conv_1 (Conv2D)                                                Relu[0][0]']                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_58 (TFOpL  (None, 1, 1, 96)    0           ['expanded_conv_3/squeeze_excite/\n",
      " ambda)                                                          Conv_1[0][0]']                   \n",
      "                                                                                                  \n",
      " re_lu_73 (ReLU)                (None, 1, 1, 96)     0           ['tf.__operators__.add_58[0][0]']\n",
      "                                                                                                  \n",
      " tf.math.multiply_58 (TFOpLambd  (None, 1, 1, 96)    0           ['re_lu_73[0][0]']               \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " expanded_conv_3/squeeze_excite  (None, 14, 14, 96)  0           ['multiply_38[0][0]',            \n",
      " /Mul (Multiply)                                                  'tf.math.multiply_58[0][0]']    \n",
      "                                                                                                  \n",
      " expanded_conv_3/project (Conv2  (None, 14, 14, 40)  3840        ['expanded_conv_3/squeeze_excite/\n",
      " D)                                                              Mul[0][0]']                      \n",
      "                                                                                                  \n",
      " expanded_conv_3/project/BatchN  (None, 14, 14, 40)  160         ['expanded_conv_3/project[0][0]']\n",
      " orm (BatchNormalization)                                                                         \n",
      "                                                                                                  \n",
      " expanded_conv_4/expand (Conv2D  (None, 14, 14, 240)  9600       ['expanded_conv_3/project/BatchNo\n",
      " )                                                               rm[0][0]']                       \n",
      "                                                                                                  \n",
      " expanded_conv_4/expand/BatchNo  (None, 14, 14, 240)  960        ['expanded_conv_4/expand[0][0]'] \n",
      " rm (BatchNormalization)                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_59 (TFOpL  (None, 14, 14, 240)  0          ['expanded_conv_4/expand/BatchNor\n",
      " ambda)                                                          m[0][0]']                        \n",
      "                                                                                                  \n",
      " re_lu_74 (ReLU)                (None, 14, 14, 240)  0           ['tf.__operators__.add_59[0][0]']\n",
      "                                                                                                  \n",
      " tf.math.multiply_59 (TFOpLambd  (None, 14, 14, 240)  0          ['re_lu_74[0][0]']               \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " multiply_39 (Multiply)         (None, 14, 14, 240)  0           ['expanded_conv_4/expand/BatchNor\n",
      "                                                                 m[0][0]',                        \n",
      "                                                                  'tf.math.multiply_59[0][0]']    \n",
      "                                                                                                  \n",
      " expanded_conv_4/depthwise (Dep  (None, 14, 14, 240)  6000       ['multiply_39[0][0]']            \n",
      " thwiseConv2D)                                                                                    \n",
      "                                                                                                  \n",
      " expanded_conv_4/depthwise/Batc  (None, 14, 14, 240)  960        ['expanded_conv_4/depthwise[0][0]\n",
      " hNorm (BatchNormalization)                                      ']                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_60 (TFOpL  (None, 14, 14, 240)  0          ['expanded_conv_4/depthwise/Batch\n",
      " ambda)                                                          Norm[0][0]']                     \n",
      "                                                                                                  \n",
      " re_lu_75 (ReLU)                (None, 14, 14, 240)  0           ['tf.__operators__.add_60[0][0]']\n",
      "                                                                                                  \n",
      " tf.math.multiply_60 (TFOpLambd  (None, 14, 14, 240)  0          ['re_lu_75[0][0]']               \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " multiply_40 (Multiply)         (None, 14, 14, 240)  0           ['expanded_conv_4/depthwise/Batch\n",
      "                                                                 Norm[0][0]',                     \n",
      "                                                                  'tf.math.multiply_60[0][0]']    \n",
      "                                                                                                  \n",
      " expanded_conv_4/squeeze_excite  (None, 1, 1, 240)   0           ['multiply_40[0][0]']            \n",
      " /AvgPool (GlobalAveragePooling                                                                   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " expanded_conv_4/squeeze_excite  (None, 1, 1, 64)    15424       ['expanded_conv_4/squeeze_excite/\n",
      " /Conv (Conv2D)                                                  AvgPool[0][0]']                  \n",
      "                                                                                                  \n",
      " expanded_conv_4/squeeze_excite  (None, 1, 1, 64)    0           ['expanded_conv_4/squeeze_excite/\n",
      " /Relu (ReLU)                                                    Conv[0][0]']                     \n",
      "                                                                                                  \n",
      " expanded_conv_4/squeeze_excite  (None, 1, 1, 240)   15600       ['expanded_conv_4/squeeze_excite/\n",
      " /Conv_1 (Conv2D)                                                Relu[0][0]']                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_61 (TFOpL  (None, 1, 1, 240)   0           ['expanded_conv_4/squeeze_excite/\n",
      " ambda)                                                          Conv_1[0][0]']                   \n",
      "                                                                                                  \n",
      " re_lu_76 (ReLU)                (None, 1, 1, 240)    0           ['tf.__operators__.add_61[0][0]']\n",
      "                                                                                                  \n",
      " tf.math.multiply_61 (TFOpLambd  (None, 1, 1, 240)   0           ['re_lu_76[0][0]']               \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " expanded_conv_4/squeeze_excite  (None, 14, 14, 240)  0          ['multiply_40[0][0]',            \n",
      " /Mul (Multiply)                                                  'tf.math.multiply_61[0][0]']    \n",
      "                                                                                                  \n",
      " expanded_conv_4/project (Conv2  (None, 14, 14, 40)  9600        ['expanded_conv_4/squeeze_excite/\n",
      " D)                                                              Mul[0][0]']                      \n",
      "                                                                                                  \n",
      " expanded_conv_4/project/BatchN  (None, 14, 14, 40)  160         ['expanded_conv_4/project[0][0]']\n",
      " orm (BatchNormalization)                                                                         \n",
      "                                                                                                  \n",
      " expanded_conv_4/Add (Add)      (None, 14, 14, 40)   0           ['expanded_conv_3/project/BatchNo\n",
      "                                                                 rm[0][0]',                       \n",
      "                                                                  'expanded_conv_4/project/BatchNo\n",
      "                                                                 rm[0][0]']                       \n",
      "                                                                                                  \n",
      " expanded_conv_5/expand (Conv2D  (None, 14, 14, 240)  9600       ['expanded_conv_4/Add[0][0]']    \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " expanded_conv_5/expand/BatchNo  (None, 14, 14, 240)  960        ['expanded_conv_5/expand[0][0]'] \n",
      " rm (BatchNormalization)                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_62 (TFOpL  (None, 14, 14, 240)  0          ['expanded_conv_5/expand/BatchNor\n",
      " ambda)                                                          m[0][0]']                        \n",
      "                                                                                                  \n",
      " re_lu_77 (ReLU)                (None, 14, 14, 240)  0           ['tf.__operators__.add_62[0][0]']\n",
      "                                                                                                  \n",
      " tf.math.multiply_62 (TFOpLambd  (None, 14, 14, 240)  0          ['re_lu_77[0][0]']               \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " multiply_41 (Multiply)         (None, 14, 14, 240)  0           ['expanded_conv_5/expand/BatchNor\n",
      "                                                                 m[0][0]',                        \n",
      "                                                                  'tf.math.multiply_62[0][0]']    \n",
      "                                                                                                  \n",
      " expanded_conv_5/depthwise (Dep  (None, 14, 14, 240)  6000       ['multiply_41[0][0]']            \n",
      " thwiseConv2D)                                                                                    \n",
      "                                                                                                  \n",
      " expanded_conv_5/depthwise/Batc  (None, 14, 14, 240)  960        ['expanded_conv_5/depthwise[0][0]\n",
      " hNorm (BatchNormalization)                                      ']                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_63 (TFOpL  (None, 14, 14, 240)  0          ['expanded_conv_5/depthwise/Batch\n",
      " ambda)                                                          Norm[0][0]']                     \n",
      "                                                                                                  \n",
      " re_lu_78 (ReLU)                (None, 14, 14, 240)  0           ['tf.__operators__.add_63[0][0]']\n",
      "                                                                                                  \n",
      " tf.math.multiply_63 (TFOpLambd  (None, 14, 14, 240)  0          ['re_lu_78[0][0]']               \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " multiply_42 (Multiply)         (None, 14, 14, 240)  0           ['expanded_conv_5/depthwise/Batch\n",
      "                                                                 Norm[0][0]',                     \n",
      "                                                                  'tf.math.multiply_63[0][0]']    \n",
      "                                                                                                  \n",
      " expanded_conv_5/squeeze_excite  (None, 1, 1, 240)   0           ['multiply_42[0][0]']            \n",
      " /AvgPool (GlobalAveragePooling                                                                   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " expanded_conv_5/squeeze_excite  (None, 1, 1, 64)    15424       ['expanded_conv_5/squeeze_excite/\n",
      " /Conv (Conv2D)                                                  AvgPool[0][0]']                  \n",
      "                                                                                                  \n",
      " expanded_conv_5/squeeze_excite  (None, 1, 1, 64)    0           ['expanded_conv_5/squeeze_excite/\n",
      " /Relu (ReLU)                                                    Conv[0][0]']                     \n",
      "                                                                                                  \n",
      " expanded_conv_5/squeeze_excite  (None, 1, 1, 240)   15600       ['expanded_conv_5/squeeze_excite/\n",
      " /Conv_1 (Conv2D)                                                Relu[0][0]']                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_64 (TFOpL  (None, 1, 1, 240)   0           ['expanded_conv_5/squeeze_excite/\n",
      " ambda)                                                          Conv_1[0][0]']                   \n",
      "                                                                                                  \n",
      " re_lu_79 (ReLU)                (None, 1, 1, 240)    0           ['tf.__operators__.add_64[0][0]']\n",
      "                                                                                                  \n",
      " tf.math.multiply_64 (TFOpLambd  (None, 1, 1, 240)   0           ['re_lu_79[0][0]']               \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " expanded_conv_5/squeeze_excite  (None, 14, 14, 240)  0          ['multiply_42[0][0]',            \n",
      " /Mul (Multiply)                                                  'tf.math.multiply_64[0][0]']    \n",
      "                                                                                                  \n",
      " expanded_conv_5/project (Conv2  (None, 14, 14, 40)  9600        ['expanded_conv_5/squeeze_excite/\n",
      " D)                                                              Mul[0][0]']                      \n",
      "                                                                                                  \n",
      " expanded_conv_5/project/BatchN  (None, 14, 14, 40)  160         ['expanded_conv_5/project[0][0]']\n",
      " orm (BatchNormalization)                                                                         \n",
      "                                                                                                  \n",
      " expanded_conv_5/Add (Add)      (None, 14, 14, 40)   0           ['expanded_conv_4/Add[0][0]',    \n",
      "                                                                  'expanded_conv_5/project/BatchNo\n",
      "                                                                 rm[0][0]']                       \n",
      "                                                                                                  \n",
      " expanded_conv_6/expand (Conv2D  (None, 14, 14, 120)  4800       ['expanded_conv_5/Add[0][0]']    \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " expanded_conv_6/expand/BatchNo  (None, 14, 14, 120)  480        ['expanded_conv_6/expand[0][0]'] \n",
      " rm (BatchNormalization)                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_65 (TFOpL  (None, 14, 14, 120)  0          ['expanded_conv_6/expand/BatchNor\n",
      " ambda)                                                          m[0][0]']                        \n",
      "                                                                                                  \n",
      " re_lu_80 (ReLU)                (None, 14, 14, 120)  0           ['tf.__operators__.add_65[0][0]']\n",
      "                                                                                                  \n",
      " tf.math.multiply_65 (TFOpLambd  (None, 14, 14, 120)  0          ['re_lu_80[0][0]']               \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " multiply_43 (Multiply)         (None, 14, 14, 120)  0           ['expanded_conv_6/expand/BatchNor\n",
      "                                                                 m[0][0]',                        \n",
      "                                                                  'tf.math.multiply_65[0][0]']    \n",
      "                                                                                                  \n",
      " expanded_conv_6/depthwise (Dep  (None, 14, 14, 120)  3000       ['multiply_43[0][0]']            \n",
      " thwiseConv2D)                                                                                    \n",
      "                                                                                                  \n",
      " expanded_conv_6/depthwise/Batc  (None, 14, 14, 120)  480        ['expanded_conv_6/depthwise[0][0]\n",
      " hNorm (BatchNormalization)                                      ']                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_66 (TFOpL  (None, 14, 14, 120)  0          ['expanded_conv_6/depthwise/Batch\n",
      " ambda)                                                          Norm[0][0]']                     \n",
      "                                                                                                  \n",
      " re_lu_81 (ReLU)                (None, 14, 14, 120)  0           ['tf.__operators__.add_66[0][0]']\n",
      "                                                                                                  \n",
      " tf.math.multiply_66 (TFOpLambd  (None, 14, 14, 120)  0          ['re_lu_81[0][0]']               \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " multiply_44 (Multiply)         (None, 14, 14, 120)  0           ['expanded_conv_6/depthwise/Batch\n",
      "                                                                 Norm[0][0]',                     \n",
      "                                                                  'tf.math.multiply_66[0][0]']    \n",
      "                                                                                                  \n",
      " expanded_conv_6/squeeze_excite  (None, 1, 1, 120)   0           ['multiply_44[0][0]']            \n",
      " /AvgPool (GlobalAveragePooling                                                                   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " expanded_conv_6/squeeze_excite  (None, 1, 1, 32)    3872        ['expanded_conv_6/squeeze_excite/\n",
      " /Conv (Conv2D)                                                  AvgPool[0][0]']                  \n",
      "                                                                                                  \n",
      " expanded_conv_6/squeeze_excite  (None, 1, 1, 32)    0           ['expanded_conv_6/squeeze_excite/\n",
      " /Relu (ReLU)                                                    Conv[0][0]']                     \n",
      "                                                                                                  \n",
      " expanded_conv_6/squeeze_excite  (None, 1, 1, 120)   3960        ['expanded_conv_6/squeeze_excite/\n",
      " /Conv_1 (Conv2D)                                                Relu[0][0]']                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_67 (TFOpL  (None, 1, 1, 120)   0           ['expanded_conv_6/squeeze_excite/\n",
      " ambda)                                                          Conv_1[0][0]']                   \n",
      "                                                                                                  \n",
      " re_lu_82 (ReLU)                (None, 1, 1, 120)    0           ['tf.__operators__.add_67[0][0]']\n",
      "                                                                                                  \n",
      " tf.math.multiply_67 (TFOpLambd  (None, 1, 1, 120)   0           ['re_lu_82[0][0]']               \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " expanded_conv_6/squeeze_excite  (None, 14, 14, 120)  0          ['multiply_44[0][0]',            \n",
      " /Mul (Multiply)                                                  'tf.math.multiply_67[0][0]']    \n",
      "                                                                                                  \n",
      " expanded_conv_6/project (Conv2  (None, 14, 14, 48)  5760        ['expanded_conv_6/squeeze_excite/\n",
      " D)                                                              Mul[0][0]']                      \n",
      "                                                                                                  \n",
      " expanded_conv_6/project/BatchN  (None, 14, 14, 48)  192         ['expanded_conv_6/project[0][0]']\n",
      " orm (BatchNormalization)                                                                         \n",
      "                                                                                                  \n",
      " expanded_conv_7/expand (Conv2D  (None, 14, 14, 144)  6912       ['expanded_conv_6/project/BatchNo\n",
      " )                                                               rm[0][0]']                       \n",
      "                                                                                                  \n",
      " expanded_conv_7/expand/BatchNo  (None, 14, 14, 144)  576        ['expanded_conv_7/expand[0][0]'] \n",
      " rm (BatchNormalization)                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_68 (TFOpL  (None, 14, 14, 144)  0          ['expanded_conv_7/expand/BatchNor\n",
      " ambda)                                                          m[0][0]']                        \n",
      "                                                                                                  \n",
      " re_lu_83 (ReLU)                (None, 14, 14, 144)  0           ['tf.__operators__.add_68[0][0]']\n",
      "                                                                                                  \n",
      " tf.math.multiply_68 (TFOpLambd  (None, 14, 14, 144)  0          ['re_lu_83[0][0]']               \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " multiply_45 (Multiply)         (None, 14, 14, 144)  0           ['expanded_conv_7/expand/BatchNor\n",
      "                                                                 m[0][0]',                        \n",
      "                                                                  'tf.math.multiply_68[0][0]']    \n",
      "                                                                                                  \n",
      " expanded_conv_7/depthwise (Dep  (None, 14, 14, 144)  3600       ['multiply_45[0][0]']            \n",
      " thwiseConv2D)                                                                                    \n",
      "                                                                                                  \n",
      " expanded_conv_7/depthwise/Batc  (None, 14, 14, 144)  576        ['expanded_conv_7/depthwise[0][0]\n",
      " hNorm (BatchNormalization)                                      ']                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_69 (TFOpL  (None, 14, 14, 144)  0          ['expanded_conv_7/depthwise/Batch\n",
      " ambda)                                                          Norm[0][0]']                     \n",
      "                                                                                                  \n",
      " re_lu_84 (ReLU)                (None, 14, 14, 144)  0           ['tf.__operators__.add_69[0][0]']\n",
      "                                                                                                  \n",
      " tf.math.multiply_69 (TFOpLambd  (None, 14, 14, 144)  0          ['re_lu_84[0][0]']               \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " multiply_46 (Multiply)         (None, 14, 14, 144)  0           ['expanded_conv_7/depthwise/Batch\n",
      "                                                                 Norm[0][0]',                     \n",
      "                                                                  'tf.math.multiply_69[0][0]']    \n",
      "                                                                                                  \n",
      " expanded_conv_7/squeeze_excite  (None, 1, 1, 144)   0           ['multiply_46[0][0]']            \n",
      " /AvgPool (GlobalAveragePooling                                                                   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " expanded_conv_7/squeeze_excite  (None, 1, 1, 40)    5800        ['expanded_conv_7/squeeze_excite/\n",
      " /Conv (Conv2D)                                                  AvgPool[0][0]']                  \n",
      "                                                                                                  \n",
      " expanded_conv_7/squeeze_excite  (None, 1, 1, 40)    0           ['expanded_conv_7/squeeze_excite/\n",
      " /Relu (ReLU)                                                    Conv[0][0]']                     \n",
      "                                                                                                  \n",
      " expanded_conv_7/squeeze_excite  (None, 1, 1, 144)   5904        ['expanded_conv_7/squeeze_excite/\n",
      " /Conv_1 (Conv2D)                                                Relu[0][0]']                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_70 (TFOpL  (None, 1, 1, 144)   0           ['expanded_conv_7/squeeze_excite/\n",
      " ambda)                                                          Conv_1[0][0]']                   \n",
      "                                                                                                  \n",
      " re_lu_85 (ReLU)                (None, 1, 1, 144)    0           ['tf.__operators__.add_70[0][0]']\n",
      "                                                                                                  \n",
      " tf.math.multiply_70 (TFOpLambd  (None, 1, 1, 144)   0           ['re_lu_85[0][0]']               \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " expanded_conv_7/squeeze_excite  (None, 14, 14, 144)  0          ['multiply_46[0][0]',            \n",
      " /Mul (Multiply)                                                  'tf.math.multiply_70[0][0]']    \n",
      "                                                                                                  \n",
      " expanded_conv_7/project (Conv2  (None, 14, 14, 48)  6912        ['expanded_conv_7/squeeze_excite/\n",
      " D)                                                              Mul[0][0]']                      \n",
      "                                                                                                  \n",
      " expanded_conv_7/project/BatchN  (None, 14, 14, 48)  192         ['expanded_conv_7/project[0][0]']\n",
      " orm (BatchNormalization)                                                                         \n",
      "                                                                                                  \n",
      " expanded_conv_7/Add (Add)      (None, 14, 14, 48)   0           ['expanded_conv_6/project/BatchNo\n",
      "                                                                 rm[0][0]',                       \n",
      "                                                                  'expanded_conv_7/project/BatchNo\n",
      "                                                                 rm[0][0]']                       \n",
      "                                                                                                  \n",
      " expanded_conv_8/expand (Conv2D  (None, 14, 14, 288)  13824      ['expanded_conv_7/Add[0][0]']    \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " expanded_conv_8/expand/BatchNo  (None, 14, 14, 288)  1152       ['expanded_conv_8/expand[0][0]'] \n",
      " rm (BatchNormalization)                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_71 (TFOpL  (None, 14, 14, 288)  0          ['expanded_conv_8/expand/BatchNor\n",
      " ambda)                                                          m[0][0]']                        \n",
      "                                                                                                  \n",
      " re_lu_86 (ReLU)                (None, 14, 14, 288)  0           ['tf.__operators__.add_71[0][0]']\n",
      "                                                                                                  \n",
      " tf.math.multiply_71 (TFOpLambd  (None, 14, 14, 288)  0          ['re_lu_86[0][0]']               \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " multiply_47 (Multiply)         (None, 14, 14, 288)  0           ['expanded_conv_8/expand/BatchNor\n",
      "                                                                 m[0][0]',                        \n",
      "                                                                  'tf.math.multiply_71[0][0]']    \n",
      "                                                                                                  \n",
      " expanded_conv_8/depthwise/pad   (None, 17, 17, 288)  0          ['multiply_47[0][0]']            \n",
      " (ZeroPadding2D)                                                                                  \n",
      "                                                                                                  \n",
      " expanded_conv_8/depthwise (Dep  (None, 7, 7, 288)   7200        ['expanded_conv_8/depthwise/pad[0\n",
      " thwiseConv2D)                                                   ][0]']                           \n",
      "                                                                                                  \n",
      " expanded_conv_8/depthwise/Batc  (None, 7, 7, 288)   1152        ['expanded_conv_8/depthwise[0][0]\n",
      " hNorm (BatchNormalization)                                      ']                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_72 (TFOpL  (None, 7, 7, 288)   0           ['expanded_conv_8/depthwise/Batch\n",
      " ambda)                                                          Norm[0][0]']                     \n",
      "                                                                                                  \n",
      " re_lu_87 (ReLU)                (None, 7, 7, 288)    0           ['tf.__operators__.add_72[0][0]']\n",
      "                                                                                                  \n",
      " tf.math.multiply_72 (TFOpLambd  (None, 7, 7, 288)   0           ['re_lu_87[0][0]']               \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " multiply_48 (Multiply)         (None, 7, 7, 288)    0           ['expanded_conv_8/depthwise/Batch\n",
      "                                                                 Norm[0][0]',                     \n",
      "                                                                  'tf.math.multiply_72[0][0]']    \n",
      "                                                                                                  \n",
      " expanded_conv_8/squeeze_excite  (None, 1, 1, 288)   0           ['multiply_48[0][0]']            \n",
      " /AvgPool (GlobalAveragePooling                                                                   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " expanded_conv_8/squeeze_excite  (None, 1, 1, 72)    20808       ['expanded_conv_8/squeeze_excite/\n",
      " /Conv (Conv2D)                                                  AvgPool[0][0]']                  \n",
      "                                                                                                  \n",
      " expanded_conv_8/squeeze_excite  (None, 1, 1, 72)    0           ['expanded_conv_8/squeeze_excite/\n",
      " /Relu (ReLU)                                                    Conv[0][0]']                     \n",
      "                                                                                                  \n",
      " expanded_conv_8/squeeze_excite  (None, 1, 1, 288)   21024       ['expanded_conv_8/squeeze_excite/\n",
      " /Conv_1 (Conv2D)                                                Relu[0][0]']                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_73 (TFOpL  (None, 1, 1, 288)   0           ['expanded_conv_8/squeeze_excite/\n",
      " ambda)                                                          Conv_1[0][0]']                   \n",
      "                                                                                                  \n",
      " re_lu_88 (ReLU)                (None, 1, 1, 288)    0           ['tf.__operators__.add_73[0][0]']\n",
      "                                                                                                  \n",
      " tf.math.multiply_73 (TFOpLambd  (None, 1, 1, 288)   0           ['re_lu_88[0][0]']               \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " expanded_conv_8/squeeze_excite  (None, 7, 7, 288)   0           ['multiply_48[0][0]',            \n",
      " /Mul (Multiply)                                                  'tf.math.multiply_73[0][0]']    \n",
      "                                                                                                  \n",
      " expanded_conv_8/project (Conv2  (None, 7, 7, 96)    27648       ['expanded_conv_8/squeeze_excite/\n",
      " D)                                                              Mul[0][0]']                      \n",
      "                                                                                                  \n",
      " expanded_conv_8/project/BatchN  (None, 7, 7, 96)    384         ['expanded_conv_8/project[0][0]']\n",
      " orm (BatchNormalization)                                                                         \n",
      "                                                                                                  \n",
      " expanded_conv_9/expand (Conv2D  (None, 7, 7, 576)   55296       ['expanded_conv_8/project/BatchNo\n",
      " )                                                               rm[0][0]']                       \n",
      "                                                                                                  \n",
      " expanded_conv_9/expand/BatchNo  (None, 7, 7, 576)   2304        ['expanded_conv_9/expand[0][0]'] \n",
      " rm (BatchNormalization)                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_74 (TFOpL  (None, 7, 7, 576)   0           ['expanded_conv_9/expand/BatchNor\n",
      " ambda)                                                          m[0][0]']                        \n",
      "                                                                                                  \n",
      " re_lu_89 (ReLU)                (None, 7, 7, 576)    0           ['tf.__operators__.add_74[0][0]']\n",
      "                                                                                                  \n",
      " tf.math.multiply_74 (TFOpLambd  (None, 7, 7, 576)   0           ['re_lu_89[0][0]']               \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " multiply_49 (Multiply)         (None, 7, 7, 576)    0           ['expanded_conv_9/expand/BatchNor\n",
      "                                                                 m[0][0]',                        \n",
      "                                                                  'tf.math.multiply_74[0][0]']    \n",
      "                                                                                                  \n",
      " expanded_conv_9/depthwise (Dep  (None, 7, 7, 576)   14400       ['multiply_49[0][0]']            \n",
      " thwiseConv2D)                                                                                    \n",
      "                                                                                                  \n",
      " expanded_conv_9/depthwise/Batc  (None, 7, 7, 576)   2304        ['expanded_conv_9/depthwise[0][0]\n",
      " hNorm (BatchNormalization)                                      ']                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_75 (TFOpL  (None, 7, 7, 576)   0           ['expanded_conv_9/depthwise/Batch\n",
      " ambda)                                                          Norm[0][0]']                     \n",
      "                                                                                                  \n",
      " re_lu_90 (ReLU)                (None, 7, 7, 576)    0           ['tf.__operators__.add_75[0][0]']\n",
      "                                                                                                  \n",
      " tf.math.multiply_75 (TFOpLambd  (None, 7, 7, 576)   0           ['re_lu_90[0][0]']               \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " multiply_50 (Multiply)         (None, 7, 7, 576)    0           ['expanded_conv_9/depthwise/Batch\n",
      "                                                                 Norm[0][0]',                     \n",
      "                                                                  'tf.math.multiply_75[0][0]']    \n",
      "                                                                                                  \n",
      " expanded_conv_9/squeeze_excite  (None, 1, 1, 576)   0           ['multiply_50[0][0]']            \n",
      " /AvgPool (GlobalAveragePooling                                                                   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " expanded_conv_9/squeeze_excite  (None, 1, 1, 144)   83088       ['expanded_conv_9/squeeze_excite/\n",
      " /Conv (Conv2D)                                                  AvgPool[0][0]']                  \n",
      "                                                                                                  \n",
      " expanded_conv_9/squeeze_excite  (None, 1, 1, 144)   0           ['expanded_conv_9/squeeze_excite/\n",
      " /Relu (ReLU)                                                    Conv[0][0]']                     \n",
      "                                                                                                  \n",
      " expanded_conv_9/squeeze_excite  (None, 1, 1, 576)   83520       ['expanded_conv_9/squeeze_excite/\n",
      " /Conv_1 (Conv2D)                                                Relu[0][0]']                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_76 (TFOpL  (None, 1, 1, 576)   0           ['expanded_conv_9/squeeze_excite/\n",
      " ambda)                                                          Conv_1[0][0]']                   \n",
      "                                                                                                  \n",
      " re_lu_91 (ReLU)                (None, 1, 1, 576)    0           ['tf.__operators__.add_76[0][0]']\n",
      "                                                                                                  \n",
      " tf.math.multiply_76 (TFOpLambd  (None, 1, 1, 576)   0           ['re_lu_91[0][0]']               \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " expanded_conv_9/squeeze_excite  (None, 7, 7, 576)   0           ['multiply_50[0][0]',            \n",
      " /Mul (Multiply)                                                  'tf.math.multiply_76[0][0]']    \n",
      "                                                                                                  \n",
      " expanded_conv_9/project (Conv2  (None, 7, 7, 96)    55296       ['expanded_conv_9/squeeze_excite/\n",
      " D)                                                              Mul[0][0]']                      \n",
      "                                                                                                  \n",
      " expanded_conv_9/project/BatchN  (None, 7, 7, 96)    384         ['expanded_conv_9/project[0][0]']\n",
      " orm (BatchNormalization)                                                                         \n",
      "                                                                                                  \n",
      " expanded_conv_9/Add (Add)      (None, 7, 7, 96)     0           ['expanded_conv_8/project/BatchNo\n",
      "                                                                 rm[0][0]',                       \n",
      "                                                                  'expanded_conv_9/project/BatchNo\n",
      "                                                                 rm[0][0]']                       \n",
      "                                                                                                  \n",
      " expanded_conv_10/expand (Conv2  (None, 7, 7, 576)   55296       ['expanded_conv_9/Add[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " expanded_conv_10/expand/BatchN  (None, 7, 7, 576)   2304        ['expanded_conv_10/expand[0][0]']\n",
      " orm (BatchNormalization)                                                                         \n",
      "                                                                                                  \n",
      " tf.__operators__.add_77 (TFOpL  (None, 7, 7, 576)   0           ['expanded_conv_10/expand/BatchNo\n",
      " ambda)                                                          rm[0][0]']                       \n",
      "                                                                                                  \n",
      " re_lu_92 (ReLU)                (None, 7, 7, 576)    0           ['tf.__operators__.add_77[0][0]']\n",
      "                                                                                                  \n",
      " tf.math.multiply_77 (TFOpLambd  (None, 7, 7, 576)   0           ['re_lu_92[0][0]']               \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " multiply_51 (Multiply)         (None, 7, 7, 576)    0           ['expanded_conv_10/expand/BatchNo\n",
      "                                                                 rm[0][0]',                       \n",
      "                                                                  'tf.math.multiply_77[0][0]']    \n",
      "                                                                                                  \n",
      " expanded_conv_10/depthwise (De  (None, 7, 7, 576)   14400       ['multiply_51[0][0]']            \n",
      " pthwiseConv2D)                                                                                   \n",
      "                                                                                                  \n",
      " expanded_conv_10/depthwise/Bat  (None, 7, 7, 576)   2304        ['expanded_conv_10/depthwise[0][0\n",
      " chNorm (BatchNormalization)                                     ]']                              \n",
      "                                                                                                  \n",
      " tf.__operators__.add_78 (TFOpL  (None, 7, 7, 576)   0           ['expanded_conv_10/depthwise/Batc\n",
      " ambda)                                                          hNorm[0][0]']                    \n",
      "                                                                                                  \n",
      " re_lu_93 (ReLU)                (None, 7, 7, 576)    0           ['tf.__operators__.add_78[0][0]']\n",
      "                                                                                                  \n",
      " tf.math.multiply_78 (TFOpLambd  (None, 7, 7, 576)   0           ['re_lu_93[0][0]']               \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " multiply_52 (Multiply)         (None, 7, 7, 576)    0           ['expanded_conv_10/depthwise/Batc\n",
      "                                                                 hNorm[0][0]',                    \n",
      "                                                                  'tf.math.multiply_78[0][0]']    \n",
      "                                                                                                  \n",
      " expanded_conv_10/squeeze_excit  (None, 1, 1, 576)   0           ['multiply_52[0][0]']            \n",
      " e/AvgPool (GlobalAveragePoolin                                                                   \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " expanded_conv_10/squeeze_excit  (None, 1, 1, 144)   83088       ['expanded_conv_10/squeeze_excite\n",
      " e/Conv (Conv2D)                                                 /AvgPool[0][0]']                 \n",
      "                                                                                                  \n",
      " expanded_conv_10/squeeze_excit  (None, 1, 1, 144)   0           ['expanded_conv_10/squeeze_excite\n",
      " e/Relu (ReLU)                                                   /Conv[0][0]']                    \n",
      "                                                                                                  \n",
      " expanded_conv_10/squeeze_excit  (None, 1, 1, 576)   83520       ['expanded_conv_10/squeeze_excite\n",
      " e/Conv_1 (Conv2D)                                               /Relu[0][0]']                    \n",
      "                                                                                                  \n",
      " tf.__operators__.add_79 (TFOpL  (None, 1, 1, 576)   0           ['expanded_conv_10/squeeze_excite\n",
      " ambda)                                                          /Conv_1[0][0]']                  \n",
      "                                                                                                  \n",
      " re_lu_94 (ReLU)                (None, 1, 1, 576)    0           ['tf.__operators__.add_79[0][0]']\n",
      "                                                                                                  \n",
      " tf.math.multiply_79 (TFOpLambd  (None, 1, 1, 576)   0           ['re_lu_94[0][0]']               \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " expanded_conv_10/squeeze_excit  (None, 7, 7, 576)   0           ['multiply_52[0][0]',            \n",
      " e/Mul (Multiply)                                                 'tf.math.multiply_79[0][0]']    \n",
      "                                                                                                  \n",
      " expanded_conv_10/project (Conv  (None, 7, 7, 96)    55296       ['expanded_conv_10/squeeze_excite\n",
      " 2D)                                                             /Mul[0][0]']                     \n",
      "                                                                                                  \n",
      " expanded_conv_10/project/Batch  (None, 7, 7, 96)    384         ['expanded_conv_10/project[0][0]'\n",
      " Norm (BatchNormalization)                                       ]                                \n",
      "                                                                                                  \n",
      " expanded_conv_10/Add (Add)     (None, 7, 7, 96)     0           ['expanded_conv_9/Add[0][0]',    \n",
      "                                                                  'expanded_conv_10/project/BatchN\n",
      "                                                                 orm[0][0]']                      \n",
      "                                                                                                  \n",
      " Conv_1 (Conv2D)                (None, 7, 7, 576)    55296       ['expanded_conv_10/Add[0][0]']   \n",
      "                                                                                                  \n",
      " Conv_1/BatchNorm (BatchNormali  (None, 7, 7, 576)   2304        ['Conv_1[0][0]']                 \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_80 (TFOpL  (None, 7, 7, 576)   0           ['Conv_1/BatchNorm[0][0]']       \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " re_lu_95 (ReLU)                (None, 7, 7, 576)    0           ['tf.__operators__.add_80[0][0]']\n",
      "                                                                                                  \n",
      " tf.math.multiply_80 (TFOpLambd  (None, 7, 7, 576)   0           ['re_lu_95[0][0]']               \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " multiply_53 (Multiply)         (None, 7, 7, 576)    0           ['Conv_1/BatchNorm[0][0]',       \n",
      "                                                                  'tf.math.multiply_80[0][0]']    \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 939,120\n",
      "Trainable params: 0\n",
      "Non-trainable params: 939,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "outputs": [],
   "source": [
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "prediction_layer = tf.keras.layers.Dense(1, activation='sigmoid')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  base_model,\n",
    "  global_average_layer,\n",
    "  prediction_layer\n",
    "])\n",
    "\n",
    "base_learning_rate = 1e-5\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=base_learning_rate),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " MobilenetV3small (Functiona  (None, 7, 7, 576)        939120    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " global_average_pooling2d_7   (None, 576)              0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 577       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 939,697\n",
      "Trainable params: 577\n",
      "Non-trainable params: 939,120\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2/200 [..............................] - ETA: 33s - loss: 0.5413 - accuracy: 0.3594"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deniz/PycharmProjects/mobilenet_finetune_exo/venv/lib/python3.7/site-packages/keras/backend.py:5677: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits, \"Sigmoid\", \"binary_crossentropy\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/200 [==================>...........] - ETA: 12s - loss: 0.5643 - accuracy: 0.3032WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 200 batches). You may need to use the repeat() function when building your dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 200 batches). You may need to use the repeat() function when building your dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 23s 114ms/step - loss: 0.5643 - accuracy: 0.3032\n"
     ]
    }
   ],
   "source": [
    "validation_steps=20\n",
    "initial_epochs = 200\n",
    "\n",
    "loss0,accuracy0 = model.evaluate(val_ds, steps = validation_steps)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 2s 179ms/step - loss: 0.6931 - accuracy: 0.5312\n"
     ]
    }
   ],
   "source": [
    "validation_steps=10\n",
    "initial_epochs = 10\n",
    "\n",
    "loss0,accuracy0 = model.evaluate(val_ds, steps = validation_steps)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "519/519 [==============================] - 632s 1s/step - loss: -0.2395 - accuracy: 0.1700 - val_loss: -0.6657 - val_accuracy: 0.1710\n",
      "Epoch 2/20\n",
      "519/519 [==============================] - 632s 1s/step - loss: -1.2277 - accuracy: 0.1528 - val_loss: -1.4597 - val_accuracy: 0.1712\n",
      "Epoch 3/20\n",
      "519/519 [==============================] - 648s 1s/step - loss: -2.1136 - accuracy: 0.1530 - val_loss: -2.2480 - val_accuracy: 0.1715\n",
      "Epoch 4/20\n",
      "  5/519 [..............................] - ETA: 10:01 - loss: -2.0745 - accuracy: 0.1813"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_9885/1275986258.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m history = model.fit(train_ds,\n\u001B[1;32m      2\u001B[0m                     \u001B[0mepochs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0minitial_epochs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m                     validation_data=val_ds)\n\u001B[0m",
      "\u001B[0;32m~/PycharmProjects/mobilenet_finetune_exo/venv/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     63\u001B[0m         \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     64\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 65\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     66\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     67\u001B[0m             \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/mobilenet_finetune_exo/venv/lib/python3.7/site-packages/keras/engine/training.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1648\u001B[0m                         ):\n\u001B[1;32m   1649\u001B[0m                             \u001B[0mcallbacks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mon_train_batch_begin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1650\u001B[0;31m                             \u001B[0mtmp_logs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1651\u001B[0m                             \u001B[0;32mif\u001B[0m \u001B[0mdata_handler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshould_sync\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1652\u001B[0m                                 \u001B[0mcontext\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0masync_wait\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/mobilenet_finetune_exo/venv/lib/python3.7/site-packages/keras/engine/training.py\u001B[0m in \u001B[0;36mtrain_function\u001B[0;34m(iterator)\u001B[0m\n\u001B[1;32m   1247\u001B[0m             \u001B[0;32mdef\u001B[0m \u001B[0mtrain_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1248\u001B[0m                 \u001B[0;34m\"\"\"Runs a training execution with a single step.\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1249\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mstep_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0miterator\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1250\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1251\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrun_eagerly\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/mobilenet_finetune_exo/venv/lib/python3.7/site-packages/keras/engine/training.py\u001B[0m in \u001B[0;36mstep_function\u001B[0;34m(model, iterator)\u001B[0m\n\u001B[1;32m   1231\u001B[0m                 )\n\u001B[1;32m   1232\u001B[0m             \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnext\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1233\u001B[0;31m             \u001B[0moutputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdistribute_strategy\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrun\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrun_step\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1234\u001B[0m             outputs = reduce_per_replica(\n\u001B[1;32m   1235\u001B[0m                 \u001B[0moutputs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/mobilenet_finetune_exo/venv/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py\u001B[0m in \u001B[0;36mrun\u001B[0;34m(***failed resolving arguments***)\u001B[0m\n\u001B[1;32m   1314\u001B[0m       fn = autograph.tf_convert(\n\u001B[1;32m   1315\u001B[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001B[0;32m-> 1316\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_extended\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcall_for_each_replica\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfn\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1317\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1318\u001B[0m   \u001B[0;32mdef\u001B[0m \u001B[0mreduce\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreduce_op\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/mobilenet_finetune_exo/venv/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py\u001B[0m in \u001B[0;36mcall_for_each_replica\u001B[0;34m(self, fn, args, kwargs)\u001B[0m\n\u001B[1;32m   2893\u001B[0m       \u001B[0mkwargs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m{\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2894\u001B[0m     \u001B[0;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_container_strategy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mscope\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2895\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_call_for_each_replica\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfn\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2896\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2897\u001B[0m   \u001B[0;32mdef\u001B[0m \u001B[0m_call_for_each_replica\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/mobilenet_finetune_exo/venv/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py\u001B[0m in \u001B[0;36m_call_for_each_replica\u001B[0;34m(self, fn, args, kwargs)\u001B[0m\n\u001B[1;32m   3694\u001B[0m   \u001B[0;32mdef\u001B[0m \u001B[0m_call_for_each_replica\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3695\u001B[0m     \u001B[0;32mwith\u001B[0m \u001B[0mReplicaContext\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_container_strategy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreplica_id_in_sync_group\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3696\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   3697\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3698\u001B[0m   \u001B[0;32mdef\u001B[0m \u001B[0m_reduce_to\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreduce_op\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdestinations\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moptions\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/mobilenet_finetune_exo/venv/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    593\u001B[0m   \u001B[0;32mdef\u001B[0m \u001B[0mwrapper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    594\u001B[0m     \u001B[0;32mwith\u001B[0m \u001B[0mag_ctx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mControlStatusCtx\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstatus\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mag_ctx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mStatus\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mUNSPECIFIED\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 595\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    596\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    597\u001B[0m   \u001B[0;32mif\u001B[0m \u001B[0minspect\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0misfunction\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfunc\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0minspect\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mismethod\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfunc\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/mobilenet_finetune_exo/venv/lib/python3.7/site-packages/keras/engine/training.py\u001B[0m in \u001B[0;36mrun_step\u001B[0;34m(data)\u001B[0m\n\u001B[1;32m   1220\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1221\u001B[0m             \u001B[0;32mdef\u001B[0m \u001B[0mrun_step\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1222\u001B[0;31m                 \u001B[0moutputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain_step\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1223\u001B[0m                 \u001B[0;31m# Ensure counter is updated only if `train_step` succeeds.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1224\u001B[0m                 \u001B[0;32mwith\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcontrol_dependencies\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m_minimum_control_deps\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0moutputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/mobilenet_finetune_exo/venv/lib/python3.7/site-packages/keras/engine/training.py\u001B[0m in \u001B[0;36mtrain_step\u001B[0;34m(self, data)\u001B[0m\n\u001B[1;32m   1021\u001B[0m         \u001B[0;31m# Run forward pass.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1022\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mGradientTape\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mtape\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1023\u001B[0;31m             \u001B[0my_pred\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtraining\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1024\u001B[0m             \u001B[0mloss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcompute_loss\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_pred\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msample_weight\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1025\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_validate_target_and_loss\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mloss\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/mobilenet_finetune_exo/venv/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     63\u001B[0m         \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     64\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 65\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     66\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     67\u001B[0m             \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/mobilenet_finetune_exo/venv/lib/python3.7/site-packages/keras/engine/training.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    559\u001B[0m             \u001B[0mlayout_map_lib\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_map_subclass_model_variable\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_layout_map\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    560\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 561\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0msuper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__call__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    562\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    563\u001B[0m     \u001B[0;34m@\u001B[0m\u001B[0mdoc_controls\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdoc_in_current_and_subclasses\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/mobilenet_finetune_exo/venv/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     63\u001B[0m         \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     64\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 65\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     66\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     67\u001B[0m             \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/mobilenet_finetune_exo/venv/lib/python3.7/site-packages/keras/engine/base_layer.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1130\u001B[0m                     \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_compute_dtype_object\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1131\u001B[0m                 ):\n\u001B[0;32m-> 1132\u001B[0;31m                     \u001B[0moutputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcall_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1133\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1134\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_activity_regularizer\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/mobilenet_finetune_exo/venv/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     94\u001B[0m         \u001B[0mbound_signature\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     95\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 96\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     97\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     98\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mhasattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"_keras_call_info_injected\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/mobilenet_finetune_exo/venv/lib/python3.7/site-packages/keras/engine/sequential.py\u001B[0m in \u001B[0;36mcall\u001B[0;34m(self, inputs, training, mask)\u001B[0m\n\u001B[1;32m    411\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbuilt\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    412\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_init_graph_network\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moutputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 413\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0msuper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcall\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtraining\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtraining\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmask\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmask\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    414\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    415\u001B[0m         \u001B[0moutputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0minputs\u001B[0m  \u001B[0;31m# handle the corner case where self.layers is empty\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/mobilenet_finetune_exo/venv/lib/python3.7/site-packages/keras/engine/functional.py\u001B[0m in \u001B[0;36mcall\u001B[0;34m(self, inputs, training, mask)\u001B[0m\n\u001B[1;32m    509\u001B[0m             \u001B[0ma\u001B[0m \u001B[0mlist\u001B[0m \u001B[0mof\u001B[0m \u001B[0mtensors\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mthere\u001B[0m \u001B[0mare\u001B[0m \u001B[0mmore\u001B[0m \u001B[0mthan\u001B[0m \u001B[0mone\u001B[0m \u001B[0moutputs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    510\u001B[0m         \"\"\"\n\u001B[0;32m--> 511\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_run_internal_graph\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtraining\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtraining\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmask\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmask\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    512\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    513\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mcompute_output_shape\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput_shape\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/mobilenet_finetune_exo/venv/lib/python3.7/site-packages/keras/engine/functional.py\u001B[0m in \u001B[0;36m_run_internal_graph\u001B[0;34m(self, inputs, training, mask)\u001B[0m\n\u001B[1;32m    666\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    667\u001B[0m                 \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnode\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmap_arguments\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtensor_dict\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 668\u001B[0;31m                 \u001B[0moutputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnode\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlayer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    669\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    670\u001B[0m                 \u001B[0;31m# Update tensor_dict.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/mobilenet_finetune_exo/venv/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     63\u001B[0m         \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     64\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 65\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     66\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     67\u001B[0m             \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/mobilenet_finetune_exo/venv/lib/python3.7/site-packages/keras/engine/training.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    559\u001B[0m             \u001B[0mlayout_map_lib\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_map_subclass_model_variable\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_layout_map\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    560\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 561\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0msuper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__call__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    562\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    563\u001B[0m     \u001B[0;34m@\u001B[0m\u001B[0mdoc_controls\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdoc_in_current_and_subclasses\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/mobilenet_finetune_exo/venv/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     63\u001B[0m         \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     64\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 65\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     66\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     67\u001B[0m             \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/mobilenet_finetune_exo/venv/lib/python3.7/site-packages/keras/engine/base_layer.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1130\u001B[0m                     \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_compute_dtype_object\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1131\u001B[0m                 ):\n\u001B[0;32m-> 1132\u001B[0;31m                     \u001B[0moutputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcall_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1133\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1134\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_activity_regularizer\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/mobilenet_finetune_exo/venv/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     94\u001B[0m         \u001B[0mbound_signature\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     95\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 96\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     97\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     98\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mhasattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"_keras_call_info_injected\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/mobilenet_finetune_exo/venv/lib/python3.7/site-packages/keras/engine/functional.py\u001B[0m in \u001B[0;36mcall\u001B[0;34m(self, inputs, training, mask)\u001B[0m\n\u001B[1;32m    509\u001B[0m             \u001B[0ma\u001B[0m \u001B[0mlist\u001B[0m \u001B[0mof\u001B[0m \u001B[0mtensors\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mthere\u001B[0m \u001B[0mare\u001B[0m \u001B[0mmore\u001B[0m \u001B[0mthan\u001B[0m \u001B[0mone\u001B[0m \u001B[0moutputs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    510\u001B[0m         \"\"\"\n\u001B[0;32m--> 511\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_run_internal_graph\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtraining\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtraining\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmask\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmask\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    512\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    513\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mcompute_output_shape\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput_shape\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/mobilenet_finetune_exo/venv/lib/python3.7/site-packages/keras/engine/functional.py\u001B[0m in \u001B[0;36m_run_internal_graph\u001B[0;34m(self, inputs, training, mask)\u001B[0m\n\u001B[1;32m    666\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    667\u001B[0m                 \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnode\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmap_arguments\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtensor_dict\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 668\u001B[0;31m                 \u001B[0moutputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnode\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlayer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    669\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    670\u001B[0m                 \u001B[0;31m# Update tensor_dict.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/mobilenet_finetune_exo/venv/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     63\u001B[0m         \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     64\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 65\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     66\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     67\u001B[0m             \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/mobilenet_finetune_exo/venv/lib/python3.7/site-packages/keras/engine/base_layer.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1130\u001B[0m                     \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_compute_dtype_object\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1131\u001B[0m                 ):\n\u001B[0;32m-> 1132\u001B[0;31m                     \u001B[0moutputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcall_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1133\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1134\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_activity_regularizer\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/mobilenet_finetune_exo/venv/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     94\u001B[0m         \u001B[0mbound_signature\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     95\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 96\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     97\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     98\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mhasattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"_keras_call_info_injected\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/mobilenet_finetune_exo/venv/lib/python3.7/site-packages/keras/layers/activation/relu.py\u001B[0m in \u001B[0;36mcall\u001B[0;34m(self, inputs)\u001B[0m\n\u001B[1;32m    107\u001B[0m             \u001B[0malpha\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnegative_slope\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    108\u001B[0m             \u001B[0mmax_value\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmax_value\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 109\u001B[0;31m             \u001B[0mthreshold\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mthreshold\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    110\u001B[0m         )\n\u001B[1;32m    111\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/mobilenet_finetune_exo/venv/lib/python3.7/site-packages/tensorflow/python/util/traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m     \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    149\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 150\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    151\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    152\u001B[0m       \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/mobilenet_finetune_exo/venv/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\u001B[0m in \u001B[0;36mop_dispatch_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m   1174\u001B[0m       \u001B[0;31m# Fallback dispatch system (dispatch v1):\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1175\u001B[0m       \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1176\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mdispatch_target\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1177\u001B[0m       \u001B[0;32mexcept\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mTypeError\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mValueError\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1178\u001B[0m         \u001B[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/mobilenet_finetune_exo/venv/lib/python3.7/site-packages/keras/backend.py\u001B[0m in \u001B[0;36mrelu\u001B[0;34m(x, alpha, max_value, threshold)\u001B[0m\n\u001B[1;32m   5364\u001B[0m     \u001B[0;32melif\u001B[0m \u001B[0mmax_value\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m6\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   5365\u001B[0m         \u001B[0;31m# if no threshold, then can use nn.relu6 native TF op for performance\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 5366\u001B[0;31m         \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrelu6\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   5367\u001B[0m         \u001B[0mclip_max\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mFalse\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   5368\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/mobilenet_finetune_exo/venv/lib/python3.7/site-packages/tensorflow/python/util/traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m     \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    149\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 150\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    151\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    152\u001B[0m       \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/mobilenet_finetune_exo/venv/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\u001B[0m in \u001B[0;36mop_dispatch_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m   1174\u001B[0m       \u001B[0;31m# Fallback dispatch system (dispatch v1):\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1175\u001B[0m       \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1176\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mdispatch_target\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1177\u001B[0m       \u001B[0;32mexcept\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mTypeError\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mValueError\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1178\u001B[0m         \u001B[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/mobilenet_finetune_exo/venv/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py\u001B[0m in \u001B[0;36mrelu6\u001B[0;34m(features, name)\u001B[0m\n\u001B[1;32m   3656\u001B[0m   \u001B[0;32mwith\u001B[0m \u001B[0mops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mname_scope\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"Relu6\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mfeatures\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3657\u001B[0m     \u001B[0mfeatures\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconvert_to_tensor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfeatures\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"features\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3658\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mgen_nn_ops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrelu6\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfeatures\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   3659\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3660\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/mobilenet_finetune_exo/venv/lib/python3.7/site-packages/tensorflow/python/ops/gen_nn_ops.py\u001B[0m in \u001B[0;36mrelu6\u001B[0;34m(features, name)\u001B[0m\n\u001B[1;32m  10789\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m  10790\u001B[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001B[0;32m> 10791\u001B[0;31m         _ctx, \"Relu6\", name, features)\n\u001B[0m\u001B[1;32m  10792\u001B[0m       \u001B[0;32mreturn\u001B[0m \u001B[0m_result\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m  10793\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0m_core\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(train_ds,\n",
    "                    epochs=initial_epochs,\n",
    "                    validation_data=val_ds)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "519/519 [==============================] - 261s 503ms/step - loss: 0.6808 - accuracy: 0.5220 - val_loss: 0.6695 - val_accuracy: 0.5125\n",
      "Epoch 2/10\n",
      "519/519 [==============================] - 261s 503ms/step - loss: 0.6573 - accuracy: 0.5220 - val_loss: 0.6470 - val_accuracy: 0.5125\n",
      "Epoch 3/10\n",
      "519/519 [==============================] - 262s 506ms/step - loss: 0.6345 - accuracy: 0.5220 - val_loss: 0.6252 - val_accuracy: 0.5125\n",
      "Epoch 4/10\n",
      "369/519 [====================>.........] - ETA: 1:09 - loss: 0.6149 - accuracy: 0.5202"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_9885/3987885461.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m history = model.fit(train_ds,\n\u001B[1;32m      2\u001B[0m                     \u001B[0mepochs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0minitial_epochs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m                     validation_data=val_ds)\n\u001B[0m\u001B[1;32m      4\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/mobilenet_finetune_exo/venv/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     63\u001B[0m         \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     64\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 65\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     66\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     67\u001B[0m             \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/mobilenet_finetune_exo/venv/lib/python3.7/site-packages/keras/engine/training.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1648\u001B[0m                         ):\n\u001B[1;32m   1649\u001B[0m                             \u001B[0mcallbacks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mon_train_batch_begin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1650\u001B[0;31m                             \u001B[0mtmp_logs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1651\u001B[0m                             \u001B[0;32mif\u001B[0m \u001B[0mdata_handler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshould_sync\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1652\u001B[0m                                 \u001B[0mcontext\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0masync_wait\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/mobilenet_finetune_exo/venv/lib/python3.7/site-packages/keras/engine/training.py\u001B[0m in \u001B[0;36mtrain_function\u001B[0;34m(iterator)\u001B[0m\n\u001B[1;32m   1247\u001B[0m             \u001B[0;32mdef\u001B[0m \u001B[0mtrain_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1248\u001B[0m                 \u001B[0;34m\"\"\"Runs a training execution with a single step.\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1249\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mstep_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0miterator\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1250\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1251\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrun_eagerly\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/mobilenet_finetune_exo/venv/lib/python3.7/site-packages/keras/engine/training.py\u001B[0m in \u001B[0;36mstep_function\u001B[0;34m(model, iterator)\u001B[0m\n\u001B[1;32m   1231\u001B[0m                 )\n\u001B[1;32m   1232\u001B[0m             \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnext\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1233\u001B[0;31m             \u001B[0moutputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdistribute_strategy\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrun\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrun_step\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1234\u001B[0m             outputs = reduce_per_replica(\n\u001B[1;32m   1235\u001B[0m                 \u001B[0moutputs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/mobilenet_finetune_exo/venv/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py\u001B[0m in \u001B[0;36mrun\u001B[0;34m(***failed resolving arguments***)\u001B[0m\n\u001B[1;32m   1314\u001B[0m       fn = autograph.tf_convert(\n\u001B[1;32m   1315\u001B[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001B[0;32m-> 1316\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_extended\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcall_for_each_replica\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfn\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1317\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1318\u001B[0m   \u001B[0;32mdef\u001B[0m \u001B[0mreduce\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreduce_op\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/mobilenet_finetune_exo/venv/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py\u001B[0m in \u001B[0;36mcall_for_each_replica\u001B[0;34m(self, fn, args, kwargs)\u001B[0m\n\u001B[1;32m   2893\u001B[0m       \u001B[0mkwargs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m{\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2894\u001B[0m     \u001B[0;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_container_strategy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mscope\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2895\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_call_for_each_replica\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfn\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2896\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2897\u001B[0m   \u001B[0;32mdef\u001B[0m \u001B[0m_call_for_each_replica\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/mobilenet_finetune_exo/venv/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py\u001B[0m in \u001B[0;36m_call_for_each_replica\u001B[0;34m(self, fn, args, kwargs)\u001B[0m\n\u001B[1;32m   3694\u001B[0m   \u001B[0;32mdef\u001B[0m \u001B[0m_call_for_each_replica\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3695\u001B[0m     \u001B[0;32mwith\u001B[0m \u001B[0mReplicaContext\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_container_strategy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreplica_id_in_sync_group\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3696\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   3697\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3698\u001B[0m   \u001B[0;32mdef\u001B[0m \u001B[0m_reduce_to\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreduce_op\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdestinations\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moptions\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/mobilenet_finetune_exo/venv/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    593\u001B[0m   \u001B[0;32mdef\u001B[0m \u001B[0mwrapper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    594\u001B[0m     \u001B[0;32mwith\u001B[0m \u001B[0mag_ctx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mControlStatusCtx\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstatus\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mag_ctx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mStatus\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mUNSPECIFIED\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 595\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    596\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    597\u001B[0m   \u001B[0;32mif\u001B[0m \u001B[0minspect\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0misfunction\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfunc\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0minspect\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mismethod\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfunc\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/mobilenet_finetune_exo/venv/lib/python3.7/site-packages/keras/engine/training.py\u001B[0m in \u001B[0;36mrun_step\u001B[0;34m(data)\u001B[0m\n\u001B[1;32m   1220\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1221\u001B[0m             \u001B[0;32mdef\u001B[0m \u001B[0mrun_step\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1222\u001B[0;31m                 \u001B[0moutputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain_step\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1223\u001B[0m                 \u001B[0;31m# Ensure counter is updated only if `train_step` succeeds.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1224\u001B[0m                 \u001B[0;32mwith\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcontrol_dependencies\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m_minimum_control_deps\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0moutputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/mobilenet_finetune_exo/venv/lib/python3.7/site-packages/keras/engine/training.py\u001B[0m in \u001B[0;36mtrain_step\u001B[0;34m(self, data)\u001B[0m\n\u001B[1;32m   1025\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_validate_target_and_loss\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mloss\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1026\u001B[0m         \u001B[0;31m# Run backwards pass.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1027\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moptimizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mminimize\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mloss\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrainable_variables\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtape\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtape\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1028\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcompute_metrics\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_pred\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msample_weight\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1029\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/mobilenet_finetune_exo/venv/lib/python3.7/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\u001B[0m in \u001B[0;36mminimize\u001B[0;34m(self, loss, var_list, tape)\u001B[0m\n\u001B[1;32m    524\u001B[0m           \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    525\u001B[0m         \"\"\"\n\u001B[0;32m--> 526\u001B[0;31m         \u001B[0mgrads_and_vars\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcompute_gradients\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mloss\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvar_list\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtape\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    527\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mapply_gradients\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mgrads_and_vars\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    528\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/mobilenet_finetune_exo/venv/lib/python3.7/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\u001B[0m in \u001B[0;36mcompute_gradients\u001B[0;34m(self, loss, var_list, tape)\u001B[0m\n\u001B[1;32m    257\u001B[0m                     \u001B[0mvar_list\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mvar_list\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    258\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 259\u001B[0;31m         \u001B[0mgrads\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtape\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgradient\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mloss\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvar_list\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    260\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mlist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mzip\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mgrads\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvar_list\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    261\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/mobilenet_finetune_exo/venv/lib/python3.7/site-packages/tensorflow/python/eager/backprop.py\u001B[0m in \u001B[0;36mgradient\u001B[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001B[0m\n\u001B[1;32m   1116\u001B[0m         \u001B[0moutput_gradients\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0moutput_gradients\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1117\u001B[0m         \u001B[0msources_raw\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mflat_sources_raw\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1118\u001B[0;31m         unconnected_gradients=unconnected_gradients)\n\u001B[0m\u001B[1;32m   1119\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1120\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_persistent\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/mobilenet_finetune_exo/venv/lib/python3.7/site-packages/tensorflow/python/eager/imperative_grad.py\u001B[0m in \u001B[0;36mimperative_grad\u001B[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001B[0m\n\u001B[1;32m     71\u001B[0m       \u001B[0moutput_gradients\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     72\u001B[0m       \u001B[0msources_raw\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 73\u001B[0;31m       compat.as_str(unconnected_gradients.value))\n\u001B[0m",
      "\u001B[0;32m~/PycharmProjects/mobilenet_finetune_exo/venv/lib/python3.7/site-packages/tensorflow/python/eager/backprop.py\u001B[0m in \u001B[0;36m_gradient_function\u001B[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001B[0m\n\u001B[1;32m    155\u001B[0m       \u001B[0mgradient_name_scope\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0mforward_pass_name_scope\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34m\"/\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    156\u001B[0m     \u001B[0;32mwith\u001B[0m \u001B[0mops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mname_scope\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mgradient_name_scope\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 157\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mgrad_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmock_op\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0mout_grads\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    158\u001B[0m   \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    159\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mgrad_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmock_op\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0mout_grads\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/mobilenet_finetune_exo/venv/lib/python3.7/site-packages/tensorflow/python/ops/nn_grad.py\u001B[0m in \u001B[0;36m_FusedBatchNormV3Grad\u001B[0;34m(op, *grad)\u001B[0m\n\u001B[1;32m    923\u001B[0m \u001B[0;34m@\u001B[0m\u001B[0mops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mRegisterGradient\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"FusedBatchNormV3\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    924\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0m_FusedBatchNormV3Grad\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mop\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0mgrad\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 925\u001B[0;31m   \u001B[0;32mreturn\u001B[0m \u001B[0m_BaseFusedBatchNormGrad\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mop\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m2\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0mgrad\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    926\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    927\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/mobilenet_finetune_exo/venv/lib/python3.7/site-packages/tensorflow/python/ops/nn_grad.py\u001B[0m in \u001B[0;36m_BaseFusedBatchNormGrad\u001B[0;34m(op, version, *grad)\u001B[0m\n\u001B[1;32m    903\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mversion\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m2\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    904\u001B[0m       \u001B[0margs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"reserve_space_3\"\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mop\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moutputs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m5\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 905\u001B[0;31m     \u001B[0mdx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdscale\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdoffset\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgrad_fun\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m**\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    906\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mdata_format\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34mb\"NCHW\"\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    907\u001B[0m       \u001B[0mdx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0marray_ops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtranspose\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m3\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m2\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/mobilenet_finetune_exo/venv/lib/python3.7/site-packages/tensorflow/python/ops/gen_nn_ops.py\u001B[0m in \u001B[0;36mfused_batch_norm_grad_v3\u001B[0;34m(y_backprop, x, scale, reserve_space_1, reserve_space_2, reserve_space_3, epsilon, data_format, is_training, name)\u001B[0m\n\u001B[1;32m   4224\u001B[0m         \u001B[0m_ctx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"FusedBatchNormGradV3\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_backprop\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mscale\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   4225\u001B[0m         \u001B[0mreserve_space_1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreserve_space_2\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreserve_space_3\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"epsilon\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mepsilon\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 4226\u001B[0;31m         \"data_format\", data_format, \"is_training\", is_training)\n\u001B[0m\u001B[1;32m   4227\u001B[0m       \u001B[0m_result\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_FusedBatchNormGradV3Output\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_make\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m_result\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   4228\u001B[0m       \u001B[0;32mreturn\u001B[0m \u001B[0m_result\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(train_ds,\n",
    "                    epochs=initial_epochs,\n",
    "                    validation_data=val_ds)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "519/519 [==============================] - 264s 509ms/step - loss: 0.4068 - accuracy: 0.1877 - val_loss: 0.2904 - val_accuracy: 0.1792\n",
      "Epoch 2/200\n",
      "519/519 [==============================] - 263s 507ms/step - loss: 0.1885 - accuracy: 0.1559 - val_loss: 0.1324 - val_accuracy: 0.1717\n",
      "Epoch 3/200\n",
      "519/519 [==============================] - 259s 499ms/step - loss: 0.0543 - accuracy: 0.1533 - val_loss: 0.0324 - val_accuracy: 0.1712\n",
      "Epoch 4/200\n",
      "519/519 [==============================] - 261s 503ms/step - loss: -0.0370 - accuracy: 0.1531 - val_loss: -0.0396 - val_accuracy: 0.1712\n",
      "Epoch 5/200\n",
      "519/519 [==============================] - 259s 500ms/step - loss: -0.1069 - accuracy: 0.1530 - val_loss: -0.0976 - val_accuracy: 0.1712\n",
      "Epoch 6/200\n",
      "519/519 [==============================] - 263s 506ms/step - loss: -0.1657 - accuracy: 0.1531 - val_loss: -0.1480 - val_accuracy: 0.1712\n",
      "Epoch 7/200\n",
      "390/519 [=====================>........] - ETA: 59s - loss: -0.2090 - accuracy: 0.1524 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_9885/1275986258.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m history = model.fit(train_ds,\n\u001B[1;32m      2\u001B[0m                     \u001B[0mepochs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0minitial_epochs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m                     validation_data=val_ds)\n\u001B[0m",
      "\u001B[0;32m~/PycharmProjects/mobilenet_finetune_exo/venv/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     63\u001B[0m         \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     64\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 65\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     66\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     67\u001B[0m             \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/mobilenet_finetune_exo/venv/lib/python3.7/site-packages/keras/engine/training.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1648\u001B[0m                         ):\n\u001B[1;32m   1649\u001B[0m                             \u001B[0mcallbacks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mon_train_batch_begin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1650\u001B[0;31m                             \u001B[0mtmp_logs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1651\u001B[0m                             \u001B[0;32mif\u001B[0m \u001B[0mdata_handler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshould_sync\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1652\u001B[0m                                 \u001B[0mcontext\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0masync_wait\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/mobilenet_finetune_exo/venv/lib/python3.7/site-packages/keras/engine/training.py\u001B[0m in \u001B[0;36mtrain_function\u001B[0;34m(iterator)\u001B[0m\n\u001B[1;32m   1247\u001B[0m             \u001B[0;32mdef\u001B[0m \u001B[0mtrain_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1248\u001B[0m                 \u001B[0;34m\"\"\"Runs a training execution with a single step.\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1249\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mstep_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0miterator\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1250\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1251\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrun_eagerly\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/mobilenet_finetune_exo/venv/lib/python3.7/site-packages/keras/engine/training.py\u001B[0m in \u001B[0;36mstep_function\u001B[0;34m(model, iterator)\u001B[0m\n\u001B[1;32m   1231\u001B[0m                 )\n\u001B[1;32m   1232\u001B[0m             \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnext\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1233\u001B[0;31m             \u001B[0moutputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdistribute_strategy\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrun\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrun_step\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1234\u001B[0m             outputs = reduce_per_replica(\n\u001B[1;32m   1235\u001B[0m                 \u001B[0moutputs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/mobilenet_finetune_exo/venv/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py\u001B[0m in \u001B[0;36mrun\u001B[0;34m(***failed resolving arguments***)\u001B[0m\n\u001B[1;32m   1314\u001B[0m       fn = autograph.tf_convert(\n\u001B[1;32m   1315\u001B[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001B[0;32m-> 1316\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_extended\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcall_for_each_replica\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfn\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1317\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1318\u001B[0m   \u001B[0;32mdef\u001B[0m \u001B[0mreduce\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreduce_op\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/mobilenet_finetune_exo/venv/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py\u001B[0m in \u001B[0;36mcall_for_each_replica\u001B[0;34m(self, fn, args, kwargs)\u001B[0m\n\u001B[1;32m   2893\u001B[0m       \u001B[0mkwargs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m{\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2894\u001B[0m     \u001B[0;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_container_strategy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mscope\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2895\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_call_for_each_replica\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfn\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2896\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2897\u001B[0m   \u001B[0;32mdef\u001B[0m \u001B[0m_call_for_each_replica\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/mobilenet_finetune_exo/venv/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py\u001B[0m in \u001B[0;36m_call_for_each_replica\u001B[0;34m(self, fn, args, kwargs)\u001B[0m\n\u001B[1;32m   3694\u001B[0m   \u001B[0;32mdef\u001B[0m \u001B[0m_call_for_each_replica\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3695\u001B[0m     \u001B[0;32mwith\u001B[0m \u001B[0mReplicaContext\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_container_strategy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreplica_id_in_sync_group\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3696\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   3697\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3698\u001B[0m   \u001B[0;32mdef\u001B[0m \u001B[0m_reduce_to\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreduce_op\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdestinations\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moptions\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/mobilenet_finetune_exo/venv/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    593\u001B[0m   \u001B[0;32mdef\u001B[0m \u001B[0mwrapper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    594\u001B[0m     \u001B[0;32mwith\u001B[0m \u001B[0mag_ctx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mControlStatusCtx\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstatus\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mag_ctx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mStatus\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mUNSPECIFIED\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 595\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    596\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    597\u001B[0m   \u001B[0;32mif\u001B[0m \u001B[0minspect\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0misfunction\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfunc\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0minspect\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mismethod\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfunc\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/mobilenet_finetune_exo/venv/lib/python3.7/site-packages/keras/engine/training.py\u001B[0m in \u001B[0;36mrun_step\u001B[0;34m(data)\u001B[0m\n\u001B[1;32m   1220\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1221\u001B[0m             \u001B[0;32mdef\u001B[0m \u001B[0mrun_step\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1222\u001B[0;31m                 \u001B[0moutputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain_step\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1223\u001B[0m                 \u001B[0;31m# Ensure counter is updated only if `train_step` succeeds.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1224\u001B[0m                 \u001B[0;32mwith\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcontrol_dependencies\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m_minimum_control_deps\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0moutputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/mobilenet_finetune_exo/venv/lib/python3.7/site-packages/keras/engine/training.py\u001B[0m in \u001B[0;36mtrain_step\u001B[0;34m(self, data)\u001B[0m\n\u001B[1;32m   1025\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_validate_target_and_loss\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mloss\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1026\u001B[0m         \u001B[0;31m# Run backwards pass.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1027\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moptimizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mminimize\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mloss\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrainable_variables\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtape\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtape\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1028\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcompute_metrics\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_pred\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msample_weight\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1029\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/mobilenet_finetune_exo/venv/lib/python3.7/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\u001B[0m in \u001B[0;36mminimize\u001B[0;34m(self, loss, var_list, tape)\u001B[0m\n\u001B[1;32m    524\u001B[0m           \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    525\u001B[0m         \"\"\"\n\u001B[0;32m--> 526\u001B[0;31m         \u001B[0mgrads_and_vars\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcompute_gradients\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mloss\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvar_list\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtape\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    527\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mapply_gradients\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mgrads_and_vars\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    528\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/mobilenet_finetune_exo/venv/lib/python3.7/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\u001B[0m in \u001B[0;36mcompute_gradients\u001B[0;34m(self, loss, var_list, tape)\u001B[0m\n\u001B[1;32m    257\u001B[0m                     \u001B[0mvar_list\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mvar_list\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    258\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 259\u001B[0;31m         \u001B[0mgrads\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtape\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgradient\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mloss\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvar_list\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    260\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mlist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mzip\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mgrads\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvar_list\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    261\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/mobilenet_finetune_exo/venv/lib/python3.7/site-packages/tensorflow/python/eager/backprop.py\u001B[0m in \u001B[0;36mgradient\u001B[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001B[0m\n\u001B[1;32m   1116\u001B[0m         \u001B[0moutput_gradients\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0moutput_gradients\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1117\u001B[0m         \u001B[0msources_raw\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mflat_sources_raw\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1118\u001B[0;31m         unconnected_gradients=unconnected_gradients)\n\u001B[0m\u001B[1;32m   1119\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1120\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_persistent\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/mobilenet_finetune_exo/venv/lib/python3.7/site-packages/tensorflow/python/eager/imperative_grad.py\u001B[0m in \u001B[0;36mimperative_grad\u001B[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001B[0m\n\u001B[1;32m     71\u001B[0m       \u001B[0moutput_gradients\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     72\u001B[0m       \u001B[0msources_raw\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 73\u001B[0;31m       compat.as_str(unconnected_gradients.value))\n\u001B[0m",
      "\u001B[0;32m~/PycharmProjects/mobilenet_finetune_exo/venv/lib/python3.7/site-packages/tensorflow/python/eager/backprop.py\u001B[0m in \u001B[0;36m_gradient_function\u001B[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001B[0m\n\u001B[1;32m    155\u001B[0m       \u001B[0mgradient_name_scope\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0mforward_pass_name_scope\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34m\"/\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    156\u001B[0m     \u001B[0;32mwith\u001B[0m \u001B[0mops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mname_scope\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mgradient_name_scope\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 157\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mgrad_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmock_op\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0mout_grads\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    158\u001B[0m   \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    159\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mgrad_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmock_op\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0mout_grads\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/mobilenet_finetune_exo/venv/lib/python3.7/site-packages/tensorflow/python/ops/nn_grad.py\u001B[0m in \u001B[0;36m_Relu6Grad\u001B[0;34m(op, grad)\u001B[0m\n\u001B[1;32m    432\u001B[0m \u001B[0;34m@\u001B[0m\u001B[0mops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mRegisterGradient\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Relu6\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    433\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0m_Relu6Grad\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mop\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgrad\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 434\u001B[0;31m   \u001B[0;32mreturn\u001B[0m \u001B[0mgen_nn_ops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrelu6_grad\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mgrad\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mop\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moutputs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    435\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    436\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/mobilenet_finetune_exo/venv/lib/python3.7/site-packages/tensorflow/python/ops/gen_nn_ops.py\u001B[0m in \u001B[0;36mrelu6_grad\u001B[0;34m(gradients, features, name)\u001B[0m\n\u001B[1;32m  10847\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m  10848\u001B[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001B[0;32m> 10849\u001B[0;31m         _ctx, \"Relu6Grad\", name, gradients, features)\n\u001B[0m\u001B[1;32m  10850\u001B[0m       \u001B[0;32mreturn\u001B[0m \u001B[0m_result\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m  10851\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0m_core\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(train_ds,\n",
    "                    epochs=initial_epochs,\n",
    "                    validation_data=val_ds)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.save('./saved_model')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "outputs": [],
   "source": [
    "import pickle"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../Human-Activity-Classification/checkpoints/CNN/CNN_bilateral_imu_emg_gon_BAND10_HOP10.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_9885/3971943396.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0;32mwith\u001B[0m \u001B[0mopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'../Human-Activity-Classification/checkpoints/CNN/CNN_bilateral_imu_emg_gon_BAND10_HOP10.pkl'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'rb'\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m     \u001B[0mBIO_train\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpickle\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '../Human-Activity-Classification/checkpoints/CNN/CNN_bilateral_imu_emg_gon_BAND10_HOP10.pkl'"
     ]
    }
   ],
   "source": [
    "with open('../Human-Activity-Classification/Heuristic/checkpoints/CNN/CNN_bilateral_imu_emg_gon_BAND10_HOP10.pkl', 'rb') as input:\n",
    "    BIO_train = pickle.load(input)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
